{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Epoch 0, Loss: 0.023144315103779515\n",
      "Epoch 100, Loss: 0.023083102108174627\n",
      "Epoch 200, Loss: 0.023027811770602546\n",
      "Epoch 300, Loss: 0.022972976607315843\n",
      "Epoch 400, Loss: 0.022918483159227298\n",
      "Epoch 500, Loss: 0.02286430353650003\n",
      "Epoch 600, Loss: 0.022810425350963576\n",
      "Epoch 700, Loss: 0.022756841402489274\n",
      "Epoch 800, Loss: 0.022703546613097175\n",
      "Epoch 900, Loss: 0.022650536820660507\n",
      "Epoch 1000, Loss: 0.022597808239154846\n",
      "Epoch 1100, Loss: 0.02254535720051456\n",
      "Epoch 1200, Loss: 0.022493180027936155\n",
      "Epoch 1300, Loss: 0.022441272974759556\n",
      "Epoch 1400, Loss: 0.022389632197675906\n",
      "Epoch 1500, Loss: 0.02233825374858049\n",
      "Epoch 1600, Loss: 0.022287133576839896\n",
      "Epoch 1700, Loss: 0.022236267537472213\n",
      "Epoch 1800, Loss: 0.022185651402679765\n",
      "Epoch 1900, Loss: 0.022135280875220115\n",
      "Epoch 2000, Loss: 0.02208515160268813\n",
      "Epoch 2100, Loss: 0.022035259192124443\n",
      "Epoch 2200, Loss: 0.021985599224574243\n",
      "Epoch 2300, Loss: 0.021936167269352977\n",
      "Epoch 2400, Loss: 0.02188695889786242\n",
      "Epoch 2500, Loss: 0.021837969696860002\n",
      "Epoch 2600, Loss: 0.021789195281124905\n",
      "Epoch 2700, Loss: 0.021740631305492794\n",
      "Epoch 2800, Loss: 0.02169227347625092\n",
      "Epoch 2900, Loss: 0.02164411756189833\n",
      "Epoch 3000, Loss: 0.02159615940328435\n",
      "Epoch 3100, Loss: 0.021548394923143394\n",
      "Epoch 3200, Loss: 0.021500820135046287\n",
      "Epoch 3300, Loss: 0.02145343115178818\n",
      "Epoch 3400, Loss: 0.021406224193231974\n",
      "Epoch 3500, Loss: 0.021359195593623693\n",
      "Epoch 3600, Loss: 0.021312341808393323\n",
      "Epoch 3700, Loss: 0.021265659420451485\n",
      "Epoch 3800, Loss: 0.021219145145989247\n",
      "Epoch 3900, Loss: 0.02117279583978518\n",
      "Epoch 4000, Loss: 0.02112660850002177\n",
      "Epoch 4100, Loss: 0.021080580272610727\n",
      "Epoch 4200, Loss: 0.021034708455025843\n",
      "Epoch 4300, Loss: 0.02098899049964078\n",
      "Epoch 4400, Loss: 0.02094342401656893\n",
      "Epoch 4500, Loss: 0.020898006776002547\n",
      "Epoch 4600, Loss: 0.02085273671004839\n",
      "Epoch 4700, Loss: 0.020807611914057847\n",
      "Epoch 4800, Loss: 0.02076263064744952\n",
      "Epoch 4900, Loss: 0.020717791334022934\n",
      "Epoch 5000, Loss: 0.020673092561762026\n",
      "Epoch 5100, Loss: 0.020628533082126935\n",
      "Epoch 5200, Loss: 0.020584111808832576\n",
      "Epoch 5300, Loss: 0.020539827816112282\n",
      "Epoch 5400, Loss: 0.02049568033646437\n",
      "Epoch 5500, Loss: 0.020451668757879692\n",
      "Epoch 5600, Loss: 0.02040779262054863\n",
      "Epoch 5700, Loss: 0.020364051613046923\n",
      "Epoch 5800, Loss: 0.02032044556800153\n",
      "Epoch 5900, Loss: 0.020276974457240086\n",
      "Epoch 6000, Loss: 0.020233638386431278\n",
      "Epoch 6100, Loss: 0.02019043758922735\n",
      "Epoch 6200, Loss: 0.020147372420925486\n",
      "Epoch 6300, Loss: 0.020104443351670328\n",
      "Epoch 6400, Loss: 0.020061650959226233\n",
      "Epoch 6500, Loss: 0.02001899592135455\n",
      "Epoch 6600, Loss: 0.01997647900783735\n",
      "Epoch 6700, Loss: 0.019934101072195547\n",
      "Epoch 6800, Loss: 0.01989186304315467\n",
      "Epoch 6900, Loss: 0.019849765915916664\n",
      "Epoch 7000, Loss: 0.019807810743299407\n",
      "Epoch 7100, Loss: 0.019765998626808678\n",
      "Epoch 7200, Loss: 0.01972433070770811\n",
      "Epoch 7300, Loss: 0.019682808158152973\n",
      "Epoch 7400, Loss: 0.019641432172451918\n",
      "Epoch 7500, Loss: 0.019600203958518313\n",
      "Epoch 7600, Loss: 0.019559124729568896\n",
      "Epoch 7700, Loss: 0.019518195696122665\n",
      "Epoch 7800, Loss: 0.019477418058347247\n",
      "Epoch 7900, Loss: 0.019436792998793785\n",
      "Epoch 8000, Loss: 0.01939632167555479\n",
      "Epoch 8100, Loss: 0.019356005215872298\n",
      "Epoch 8200, Loss: 0.019315844710217352\n",
      "Epoch 8300, Loss: 0.01927584120685452\n",
      "Epoch 8400, Loss: 0.019235995706899513\n",
      "Epoch 8500, Loss: 0.019196309159871618\n",
      "Epoch 8600, Loss: 0.01915678245973781\n",
      "Epoch 8700, Loss: 0.019117416441440372\n",
      "Epoch 8800, Loss: 0.01907821187789638\n",
      "Epoch 8900, Loss: 0.019039169477453804\n",
      "Epoch 9000, Loss: 0.019000289881786668\n",
      "Epoch 9100, Loss: 0.018961573664209655\n",
      "Epoch 9200, Loss: 0.018923021328391465\n",
      "Epoch 9300, Loss: 0.01888463330744539\n",
      "Epoch 9400, Loss: 0.018846409963375287\n",
      "Epoch 9500, Loss: 0.018808351586855513\n",
      "Epoch 9600, Loss: 0.018770458397323574\n",
      "Epoch 9700, Loss: 0.018732730543365213\n",
      "Epoch 9800, Loss: 0.01869516810337243\n",
      "Epoch 9900, Loss: 0.018657771086455836\n",
      "Epoch 10000, Loss: 0.01862053943359403\n",
      "Epoch 10100, Loss: 0.018583473019003243\n",
      "Epoch 10200, Loss: 0.01854657165171178\n",
      "Epoch 10300, Loss: 0.01850983507732431\n",
      "Epoch 10400, Loss: 0.018473262979961942\n",
      "Epoch 10500, Loss: 0.01843685498436422\n",
      "Epoch 10600, Loss: 0.01840061065813979\n",
      "Epoch 10700, Loss: 0.01836452951415253\n",
      "Epoch 10800, Loss: 0.018328611013029954\n",
      "Epoch 10900, Loss: 0.01829285456578069\n",
      "Epoch 11000, Loss: 0.018257259536507447\n",
      "Epoch 11100, Loss: 0.018221825245201873\n",
      "Epoch 11200, Loss: 0.01818655097060699\n",
      "Epoch 11300, Loss: 0.018151435953132834\n",
      "Epoch 11400, Loss: 0.018116479397810387\n",
      "Epoch 11500, Loss: 0.018081680477268606\n",
      "Epoch 11600, Loss: 0.018047038334718924\n",
      "Epoch 11700, Loss: 0.01801255208693175\n",
      "Epoch 11800, Loss: 0.017978220827188956\n",
      "Epoch 11900, Loss: 0.017944043628196755\n",
      "Epoch 12000, Loss: 0.017910019544943357\n",
      "Epoch 12100, Loss: 0.01787614761748625\n",
      "Epoch 12200, Loss: 0.017842426873654206\n",
      "Epoch 12300, Loss: 0.017808856331650157\n",
      "Epoch 12400, Loss: 0.017775435002541504\n",
      "Epoch 12500, Loss: 0.017742161892625716\n",
      "Epoch 12600, Loss: 0.017709036005659887\n",
      "Epoch 12700, Loss: 0.017676056344944464\n",
      "Epoch 12800, Loss: 0.017643221915252503\n",
      "Epoch 12900, Loss: 0.01761053172459734\n",
      "Epoch 13000, Loss: 0.01757798478583314\n",
      "Epoch 13100, Loss: 0.017545580118084353\n",
      "Epoch 13200, Loss: 0.017513316748001682\n",
      "Epoch 13300, Loss: 0.017481193710843952\n",
      "Epoch 13400, Loss: 0.017449210051386672\n",
      "Epoch 13500, Loss: 0.017417364824660046\n",
      "Epoch 13600, Loss: 0.017385657096520162\n",
      "Epoch 13700, Loss: 0.01735408594405923\n",
      "Epoch 13800, Loss: 0.017322650455861517\n",
      "Epoch 13900, Loss: 0.01729134973211316\n",
      "Epoch 14000, Loss: 0.017260182884575186\n",
      "Epoch 14100, Loss: 0.017229149036429803\n",
      "Epoch 14200, Loss: 0.017198247322011192\n",
      "Epoch 14300, Loss: 0.01716747688643227\n",
      "Epoch 14400, Loss: 0.01713683688511981\n",
      "Epoch 14500, Loss: 0.017106326483270328\n",
      "Epoch 14600, Loss: 0.017075944855239424\n",
      "Epoch 14700, Loss: 0.017045691183877297\n",
      "Epoch 14800, Loss: 0.017015564659822912\n",
      "Epoch 14900, Loss: 0.016985564480769114\n",
      "Epoch 15000, Loss: 0.016955689850710432\n",
      "Epoch 15100, Loss: 0.016925939979184856\n",
      "Epoch 15200, Loss: 0.01689631408052017\n",
      "Epoch 15300, Loss: 0.016866811373094676\n",
      "Epoch 15400, Loss: 0.016837431078621318\n",
      "Epoch 15500, Loss: 0.016808172421463353\n",
      "Epoch 15600, Loss: 0.01677903462798871\n",
      "Epoch 15700, Loss: 0.016750016925969346\n",
      "Epoch 15800, Loss: 0.016721118544030755\n",
      "Epoch 15900, Loss: 0.016692338711156\n",
      "Epoch 16000, Loss: 0.01666367665624758\n",
      "Epoch 16100, Loss: 0.016635131607749532\n",
      "Epoch 16200, Loss: 0.016606702793331297\n",
      "Epoch 16300, Loss: 0.01657838943963395\n",
      "Epoch 16400, Loss: 0.01655019077207884\n",
      "Epoch 16500, Loss: 0.01652210601473764\n",
      "Epoch 16600, Loss: 0.01649413439026244\n",
      "Epoch 16700, Loss: 0.01646627511987373\n",
      "Epoch 16800, Loss: 0.016438527423403723\n",
      "Epoch 16900, Loss: 0.01641089051939198\n",
      "Epoch 17000, Loss: 0.016383363625229963\n",
      "Epoch 17100, Loss: 0.016355945957350716\n",
      "Epoch 17200, Loss: 0.016328636731459952\n",
      "Epoch 17300, Loss: 0.016301435162804242\n",
      "Epoch 17400, Loss: 0.01627434046647225\n",
      "Epoch 17500, Loss: 0.016247351857724794\n",
      "Epoch 17600, Loss: 0.016220468552349362\n",
      "Epoch 17700, Loss: 0.016193689767035148\n",
      "Epoch 17800, Loss: 0.016167014719764266\n",
      "Epoch 17900, Loss: 0.016140442630215458\n",
      "Epoch 18000, Loss: 0.016113972720176346\n",
      "Epoch 18100, Loss: 0.016087604213960705\n",
      "Epoch 18200, Loss: 0.01606133633882742\n",
      "Epoch 18300, Loss: 0.01603516832539791\n",
      "Epoch 18400, Loss: 0.016009099408069213\n",
      "Epoch 18500, Loss: 0.015983128825420016\n",
      "Epoch 18600, Loss: 0.01595725582060729\n",
      "Epoch 18700, Loss: 0.015931479641751303\n",
      "Epoch 18800, Loss: 0.015905799542307298\n",
      "Epoch 18900, Loss: 0.015880214781421997\n",
      "Epoch 19000, Loss: 0.015854724624273706\n",
      "Epoch 19100, Loss: 0.01582932834239483\n",
      "Epoch 19200, Loss: 0.015804025213975736\n",
      "Epoch 19300, Loss: 0.015778814524149455\n",
      "Epoch 19400, Loss: 0.01575369556525654\n",
      "Epoch 19500, Loss: 0.01572866763708975\n",
      "Epoch 19600, Loss: 0.0157037300471185\n",
      "Epoch 19700, Loss: 0.015678882110692856\n",
      "Epoch 19800, Loss: 0.015654123151227453\n",
      "Epoch 19900, Loss: 0.015629452500365303\n",
      "Epoch 20000, Loss: 0.015604869498122075\n",
      "Epoch 20100, Loss: 0.015580373493011137\n",
      "Epoch 20200, Loss: 0.01555596384214996\n",
      "Epoch 20300, Loss: 0.015531639911348476\n",
      "Epoch 20400, Loss: 0.015507401075180048\n",
      "Epoch 20500, Loss: 0.015483246717035697\n",
      "Epoch 20600, Loss: 0.015459176229162394\n",
      "Epoch 20700, Loss: 0.01543518901268612\n",
      "Epoch 20800, Loss: 0.015411284477620505\n",
      "Epoch 20900, Loss: 0.01538746204286179\n",
      "Epoch 21000, Loss: 0.015363721136170945\n",
      "Epoch 21100, Loss: 0.015340061194143648\n",
      "Epoch 21200, Loss: 0.015316481662168988\n",
      "Epoch 21300, Loss: 0.015292981994377538\n",
      "Epoch 21400, Loss: 0.015269561653579613\n",
      "Epoch 21500, Loss: 0.015246220111194416\n",
      "Epoch 21600, Loss: 0.01522295684717067\n",
      "Epoch 21700, Loss: 0.015199771349899562\n",
      "Epoch 21800, Loss: 0.015176663116120426\n",
      "Epoch 21900, Loss: 0.015153631650819966\n",
      "Epoch 22000, Loss: 0.015130676467125457\n",
      "Epoch 22100, Loss: 0.015107797086192514\n",
      "Epoch 22200, Loss: 0.015084993037087994\n",
      "Epoch 22300, Loss: 0.015062263856668418\n",
      "Epoch 22400, Loss: 0.015039609089454477\n",
      "Epoch 22500, Loss: 0.015017028287502029\n",
      "Epoch 22600, Loss: 0.014994521010269863\n",
      "Epoch 22700, Loss: 0.014972086824484927\n",
      "Epoch 22800, Loss: 0.014949725304005002\n",
      "Epoch 22900, Loss: 0.014927436029679508\n",
      "Epoch 23000, Loss: 0.014905218589208456\n",
      "Epoch 23100, Loss: 0.014883072577000145\n",
      "Epoch 23200, Loss: 0.014860997594027628\n",
      "Epoch 23300, Loss: 0.01483899324768441\n",
      "Epoch 23400, Loss: 0.014817059151639488\n",
      "Epoch 23500, Loss: 0.014795194925692062\n",
      "Epoch 23600, Loss: 0.014773400195626124\n",
      "Epoch 23700, Loss: 0.014751674593065105\n",
      "Epoch 23800, Loss: 0.014730017755326784\n",
      "Epoch 23900, Loss: 0.01470842932527874\n",
      "Epoch 24000, Loss: 0.014686908951194368\n",
      "Epoch 24100, Loss: 0.014665456286609773\n",
      "Epoch 24200, Loss: 0.014644070990181621\n",
      "Epoch 24300, Loss: 0.014622752725546157\n",
      "Epoch 24400, Loss: 0.014601501161179442\n",
      "Epoch 24500, Loss: 0.014580315970259102\n",
      "Epoch 24600, Loss: 0.014559196830527536\n",
      "Epoch 24700, Loss: 0.014538143424156841\n",
      "Epoch 24800, Loss: 0.014517155437615515\n",
      "Epoch 24900, Loss: 0.014496232561537032\n",
      "Epoch 25000, Loss: 0.014475374490590425\n",
      "Epoch 25100, Loss: 0.014454580923352936\n",
      "Epoch 25200, Loss: 0.014433851562184819\n",
      "Epoch 25300, Loss: 0.014413186113106415\n",
      "Epoch 25400, Loss: 0.01439258428567745\n",
      "Epoch 25500, Loss: 0.014372045792878835\n",
      "Epoch 25600, Loss: 0.01435157035099671\n",
      "Epoch 25700, Loss: 0.014331157679509085\n",
      "Epoch 25800, Loss: 0.014310807500974892\n",
      "Epoch 25900, Loss: 0.014290519540925585\n",
      "Epoch 26000, Loss: 0.014270293527759256\n",
      "Epoch 26100, Loss: 0.01425012919263731\n",
      "Epoch 26200, Loss: 0.014230026269383656\n",
      "Epoch 26300, Loss: 0.014209984494386466\n",
      "Epoch 26400, Loss: 0.014190003606502403\n",
      "Epoch 26500, Loss: 0.014170083346963385\n",
      "Epoch 26600, Loss: 0.014150223459285786\n",
      "Epoch 26700, Loss: 0.014130423689182044\n",
      "Epoch 26800, Loss: 0.014110683784474639\n",
      "Epoch 26900, Loss: 0.014091003495012423\n",
      "Epoch 27000, Loss: 0.014071382572589164\n",
      "Epoch 27100, Loss: 0.014051820770864263\n",
      "Epoch 27200, Loss: 0.014032317845285662\n",
      "Epoch 27300, Loss: 0.014012873553014693\n",
      "Epoch 27400, Loss: 0.013993487652852972\n",
      "Epoch 27500, Loss: 0.013974159905171132\n",
      "Epoch 27600, Loss: 0.01395489007183933\n",
      "Epoch 27700, Loss: 0.01393567791615954\n",
      "Epoch 27800, Loss: 0.013916523202799364\n",
      "Epoch 27900, Loss: 0.013897425697727528\n",
      "Epoch 28000, Loss: 0.013878385168150677\n",
      "Epoch 28100, Loss: 0.013859401382451722\n",
      "Epoch 28200, Loss: 0.013840474110129347\n",
      "Epoch 28300, Loss: 0.013821603121738881\n",
      "Epoch 28400, Loss: 0.013802788188834314\n",
      "Epoch 28500, Loss: 0.013784029083911376\n",
      "Epoch 28600, Loss: 0.013765325580351854\n",
      "Epoch 28700, Loss: 0.013746677452368763\n",
      "Epoch 28800, Loss: 0.0137280844749527\n",
      "Epoch 28900, Loss: 0.013709546423819123\n",
      "Epoch 29000, Loss: 0.013691063075356615\n",
      "Epoch 29100, Loss: 0.01367263420657617\n",
      "Epoch 29200, Loss: 0.013654259595061481\n",
      "Epoch 29300, Loss: 0.013635939018920285\n",
      "Epoch 29400, Loss: 0.01361767225673672\n",
      "Epoch 29500, Loss: 0.01359945908752488\n",
      "Epoch 29600, Loss: 0.01358129929068346\n",
      "Epoch 29700, Loss: 0.01356319264595171\n",
      "Epoch 29800, Loss: 0.013545138933366663\n",
      "Epoch 29900, Loss: 0.01352713793322174\n",
      "Epoch 30000, Loss: 0.013509189426026863\n",
      "Epoch 30100, Loss: 0.013491293192470142\n",
      "Epoch 30200, Loss: 0.013473449013381197\n",
      "Epoch 30300, Loss: 0.013455656669696253\n",
      "Epoch 30400, Loss: 0.01343791594242513\n",
      "Epoch 30500, Loss: 0.013420226612620115\n",
      "Epoch 30600, Loss: 0.01340258846134702\n",
      "Epoch 30700, Loss: 0.01338500126965823\n",
      "Epoch 30800, Loss: 0.013367464818568152\n",
      "Epoch 30900, Loss: 0.013349978889030844\n",
      "Epoch 31000, Loss: 0.013332543261920135\n",
      "Epoch 31100, Loss: 0.013315157718012158\n",
      "Epoch 31200, Loss: 0.013297822037970402\n",
      "Epoch 31300, Loss: 0.013280536002333346\n",
      "Epoch 31400, Loss: 0.013263299391504654\n",
      "Epoch 31500, Loss: 0.013246111985746\n",
      "Epoch 31600, Loss: 0.01322897356517251\n",
      "Epoch 31700, Loss: 0.013211883909750814\n",
      "Epoch 31800, Loss: 0.013194842799299685\n",
      "Epoch 31900, Loss: 0.013177850013493265\n",
      "Epoch 32000, Loss: 0.013160905331866785\n",
      "Epoch 32100, Loss: 0.013144008533824716\n",
      "Epoch 32200, Loss: 0.013127159398651382\n",
      "Epoch 32300, Loss: 0.013110357705523826\n",
      "Epoch 32400, Loss: 0.01309360323352686\n",
      "Epoch 32500, Loss: 0.013076895761670286\n",
      "Epoch 32600, Loss: 0.013060235068908087\n",
      "Epoch 32700, Loss: 0.013043620934159452\n",
      "Epoch 32800, Loss: 0.013027053136331629\n",
      "Epoch 32900, Loss: 0.013010531454344292\n",
      "Epoch 33000, Loss: 0.012994055667155469\n",
      "Epoch 33100, Loss: 0.012977625553788737\n",
      "Epoch 33200, Loss: 0.012961240893361647\n",
      "Epoch 33300, Loss: 0.012944901465115143\n",
      "Epoch 33400, Loss: 0.012928607048443907\n",
      "Epoch 33500, Loss: 0.01291235742292743\n",
      "Epoch 33600, Loss: 0.012896152368361703\n",
      "Epoch 33700, Loss: 0.012879991664791321\n",
      "Epoch 33800, Loss: 0.01286387509254196\n",
      "Epoch 33900, Loss: 0.012847802432252963\n",
      "Epoch 34000, Loss: 0.012831773464910084\n",
      "Epoch 34100, Loss: 0.012815787971878025\n",
      "Epoch 34200, Loss: 0.012799845734932903\n",
      "Epoch 34300, Loss: 0.01278394653629432\n",
      "Epoch 34400, Loss: 0.012768090158657085\n",
      "Epoch 34500, Loss: 0.012752276385222378\n",
      "Epoch 34600, Loss: 0.01273650499972834\n",
      "Epoch 34700, Loss: 0.012720775786479982\n",
      "Epoch 34800, Loss: 0.0127050885303783\n",
      "Epoch 34900, Loss: 0.012689443016948588\n",
      "Epoch 35000, Loss: 0.01267383903236788\n",
      "Epoch 35100, Loss: 0.012658276363491367\n",
      "Epoch 35200, Loss: 0.012642754797877942\n",
      "Epoch 35300, Loss: 0.012627274123814605\n",
      "Epoch 35400, Loss: 0.012611834130339904\n",
      "Epoch 35500, Loss: 0.012596434607266224\n",
      "Epoch 35600, Loss: 0.012581075345201042\n",
      "Epoch 35700, Loss: 0.012565756135567008\n",
      "Epoch 35800, Loss: 0.012550476770620989\n",
      "Epoch 35900, Loss: 0.01253523704347193\n",
      "Epoch 36000, Loss: 0.01252003674809769\n",
      "Epoch 36100, Loss: 0.012504875679360726\n",
      "Epoch 36200, Loss: 0.012489753633022755\n",
      "Epoch 36300, Loss: 0.012474670405758347\n",
      "Epoch 36400, Loss: 0.012459625795167517\n",
      "Epoch 36500, Loss: 0.012444619599787318\n",
      "Epoch 36600, Loss: 0.012429651619102493\n",
      "Epoch 36700, Loss: 0.01241472165355523\n",
      "Epoch 36800, Loss: 0.012399829504554009\n",
      "Epoch 36900, Loss: 0.012384974974481674\n",
      "Epoch 37000, Loss: 0.012370157866702685\n",
      "Epoch 37100, Loss: 0.012355377985569675\n",
      "Epoch 37200, Loss: 0.012340635136429306\n",
      "Epoch 37300, Loss: 0.012325929125627518\n",
      "Epoch 37400, Loss: 0.012311259760514176\n",
      "Epoch 37500, Loss: 0.01229662684944722\n",
      "Epoch 37600, Loss: 0.01228203020179636\n",
      "Epoch 37700, Loss: 0.012267469627946321\n",
      "Epoch 37800, Loss: 0.012252944939299756\n",
      "Epoch 37900, Loss: 0.012238455948279844\n",
      "Epoch 38000, Loss: 0.01222400246833265\n",
      "Epoch 38100, Loss: 0.012209584313929269\n",
      "Epoch 38200, Loss: 0.012195201300567808\n",
      "Epoch 38300, Loss: 0.012180853244775294\n",
      "Epoch 38400, Loss: 0.012166539964109525\n",
      "Epoch 38500, Loss: 0.012152261277160887\n",
      "Epoch 38600, Loss: 0.012138017003554215\n",
      "Epoch 38700, Loss: 0.012123806963950753\n",
      "Epoch 38800, Loss: 0.012109630980050218\n",
      "Epoch 38900, Loss: 0.012095488874592965\n",
      "Epoch 39000, Loss: 0.012081380471362436\n",
      "Epoch 39100, Loss: 0.012067305595187743\n",
      "Epoch 39200, Loss: 0.012053264071946516\n",
      "Epoch 39300, Loss: 0.012039255728568038\n",
      "Epoch 39400, Loss: 0.012025280393036655\n",
      "Epoch 39500, Loss: 0.012011337894395513\n",
      "Epoch 39600, Loss: 0.011997428062750571\n",
      "Epoch 39700, Loss: 0.01198355072927502\n",
      "Epoch 39800, Loss: 0.011969705726214029\n",
      "Epoch 39900, Loss: 0.01195589288688979\n",
      "Epoch 40000, Loss: 0.011942112045706983\n",
      "Epoch 40100, Loss: 0.011928363038158595\n",
      "Epoch 40200, Loss: 0.011914645700832033\n",
      "Epoch 40300, Loss: 0.011900959871415637\n",
      "Epoch 40400, Loss: 0.011887305388705508\n",
      "Epoch 40500, Loss: 0.011873682092612648\n",
      "Epoch 40600, Loss: 0.011860089824170424\n",
      "Epoch 40700, Loss: 0.011846528425542294\n",
      "Epoch 40800, Loss: 0.011832997740029823\n",
      "Epoch 40900, Loss: 0.01181949761208091\n",
      "Epoch 41000, Loss: 0.011806027887298244\n",
      "Epoch 41100, Loss: 0.011792588412447938\n",
      "Epoch 41200, Loss: 0.011779179035468327\n",
      "Epoch 41300, Loss: 0.011765799605478838\n",
      "Epoch 41400, Loss: 0.011752449972788997\n",
      "Epoch 41500, Loss: 0.01173912998890743\n",
      "Epoch 41600, Loss: 0.011725839506550916\n",
      "Epoch 41700, Loss: 0.01171257837965334\n",
      "Epoch 41800, Loss: 0.011699346463374621\n",
      "Epoch 41900, Loss: 0.011686143614109483\n",
      "Epoch 42000, Loss: 0.011672969689496094\n",
      "Epoch 42100, Loss: 0.011659824548424439\n",
      "Epoch 42200, Loss: 0.01164670805104449\n",
      "Epoch 42300, Loss: 0.011633620058774071\n",
      "Epoch 42400, Loss: 0.011620560434306336\n",
      "Epoch 42500, Loss: 0.01160752904161689\n",
      "Epoch 42600, Loss: 0.0115945257459705\n",
      "Epoch 42700, Loss: 0.011581550413927269\n",
      "Epoch 42800, Loss: 0.011568602913348366\n",
      "Epoch 42900, Loss: 0.011555683113401136\n",
      "Epoch 43000, Loss: 0.011542790884563654\n",
      "Epoch 43100, Loss: 0.011529926098628636\n",
      "Epoch 43200, Loss: 0.011517088628706674\n",
      "Epoch 43300, Loss: 0.011504278349228788\n",
      "Epoch 43400, Loss: 0.011491495135948238\n",
      "Epoch 43500, Loss: 0.011478738865941555\n",
      "Epoch 43600, Loss: 0.01146600941760883\n",
      "Epoch 43700, Loss: 0.011453306670673173\n",
      "Epoch 43800, Loss: 0.01144063050617933\n",
      "Epoch 43900, Loss: 0.011427980806491466\n",
      "Epoch 44000, Loss: 0.011415357455290117\n",
      "Epoch 44100, Loss: 0.011402760337568214\n",
      "Epoch 44200, Loss: 0.011390189339626274\n",
      "Epoch 44300, Loss: 0.011377644349066698\n",
      "Epoch 44400, Loss: 0.011365125254787174\n",
      "Epoch 44500, Loss: 0.011352631946973186\n",
      "Epoch 44600, Loss: 0.011340164317089684\n",
      "Epoch 44700, Loss: 0.011327722257871833\n",
      "Epoch 44800, Loss: 0.011315305663314939\n",
      "Epoch 44900, Loss: 0.011302914428663494\n",
      "Epoch 45000, Loss: 0.011290548450399411\n",
      "Epoch 45100, Loss: 0.011278207626229442\n",
      "Epoch 45200, Loss: 0.011265891855071779\n",
      "Epoch 45300, Loss: 0.011253601037041913\n",
      "Epoch 45400, Loss: 0.011241335073437742\n",
      "Epoch 45500, Loss: 0.011229093866723943\n",
      "Epoch 45600, Loss: 0.01121687732051568\n",
      "Epoch 45700, Loss: 0.011204685339561636\n",
      "Epoch 45800, Loss: 0.01119251782972644\n",
      "Epoch 45900, Loss: 0.011180374697972487\n",
      "Epoch 46000, Loss: 0.011168255852341212\n",
      "Epoch 46100, Loss: 0.011156161201933839\n",
      "Epoch 46200, Loss: 0.011144090656891684\n",
      "Epoch 46300, Loss: 0.011132044128375948\n",
      "Epoch 46400, Loss: 0.011120021528547184\n",
      "Epoch 46500, Loss: 0.011108022770544346\n",
      "Epoch 46600, Loss: 0.011096047768463548\n",
      "Epoch 46700, Loss: 0.011084096437336523\n",
      "Epoch 46800, Loss: 0.011072168693108847\n",
      "Epoch 46900, Loss: 0.011060264452617957\n",
      "Epoch 47000, Loss: 0.01104838363357103\n",
      "Epoch 47100, Loss: 0.011036526154522708\n",
      "Epoch 47200, Loss: 0.011024691934852768\n",
      "Epoch 47300, Loss: 0.01101288089474375\n",
      "Epoch 47400, Loss: 0.011001092955158592\n",
      "Epoch 47500, Loss: 0.010989328037818274\n",
      "Epoch 47600, Loss: 0.010977586065179588\n",
      "Epoch 47700, Loss: 0.010965866960412999\n",
      "Epoch 47800, Loss: 0.010954170647380666\n",
      "Epoch 47900, Loss: 0.010942497050614638\n",
      "Epoch 48000, Loss: 0.01093084609529534\n",
      "Epoch 48100, Loss: 0.010919217707230259\n",
      "Epoch 48200, Loss: 0.010907611812832948\n",
      "Epoch 48300, Loss: 0.010896028339102398\n",
      "Epoch 48400, Loss: 0.010884467213602743\n",
      "Epoch 48500, Loss: 0.010872928364443375\n",
      "Epoch 48600, Loss: 0.010861411720259473\n",
      "Epoch 48700, Loss: 0.010849917210193061\n",
      "Epoch 48800, Loss: 0.010838444763874439\n",
      "Epoch 48900, Loss: 0.010826994311404246\n",
      "Epoch 49000, Loss: 0.010815565783335986\n",
      "Epoch 49100, Loss: 0.010804159110659144\n",
      "Epoch 49200, Loss: 0.010792774224782913\n",
      "Epoch 49300, Loss: 0.01078141105752048\n",
      "Epoch 49400, Loss: 0.010770069541073995\n",
      "Epoch 49500, Loss: 0.010758749608020127\n",
      "Epoch 49600, Loss: 0.01074745119129633\n",
      "Epoch 49700, Loss: 0.010736174224187755\n",
      "Epoch 49800, Loss: 0.010724918640314841\n",
      "Epoch 49900, Loss: 0.010713684373621628\n",
      "Epoch 50000, Loss: 0.010702471358364737\n",
      "Epoch 50100, Loss: 0.01069127952910308\n",
      "Epoch 50200, Loss: 0.010680108820688265\n",
      "Epoch 50300, Loss: 0.010668959168255724\n",
      "Epoch 50400, Loss: 0.010657830507216538\n",
      "Epoch 50500, Loss: 0.010646722773249972\n",
      "Epoch 50600, Loss: 0.010635635902296709\n",
      "Epoch 50700, Loss: 0.01062456983055278\n",
      "Epoch 50800, Loss: 0.010613524494464186\n",
      "Epoch 50900, Loss: 0.010602499830722163\n",
      "Epoch 51000, Loss: 0.010591495776259154\n",
      "Epoch 51100, Loss: 0.010580512268245365\n",
      "Epoch 51200, Loss: 0.010569549244086027\n",
      "Epoch 51300, Loss: 0.010558606641419202\n",
      "Epoch 51400, Loss: 0.010547684398114198\n",
      "Epoch 51500, Loss: 0.010536782452270585\n",
      "Epoch 51600, Loss: 0.01052590074221772\n",
      "Epoch 51700, Loss: 0.010515039206514832\n",
      "Epoch 51800, Loss: 0.010504197783951568\n",
      "Epoch 51900, Loss: 0.010493376413549069\n",
      "Epoch 52000, Loss: 0.01048257503456143\n",
      "Epoch 52100, Loss: 0.010471793586477655\n",
      "Epoch 52200, Loss: 0.010461032009023954\n",
      "Epoch 52300, Loss: 0.01045029024216643\n",
      "Epoch 52400, Loss: 0.010439568226114112\n",
      "Epoch 52500, Loss: 0.010428865901322292\n",
      "Epoch 52600, Loss: 0.01041818320849614\n",
      "Epoch 52700, Loss: 0.0104075200885946\n",
      "Epoch 52800, Loss: 0.010396876482834487\n",
      "Epoch 52900, Loss: 0.010386252332694806\n",
      "Epoch 53000, Loss: 0.010375647579921215\n",
      "Epoch 53100, Loss: 0.010365062166530662\n",
      "Epoch 53200, Loss: 0.010354496034816139\n",
      "Epoch 53300, Loss: 0.0103439491273515\n",
      "Epoch 53400, Loss: 0.010333421386996377\n",
      "Epoch 53500, Loss: 0.010322912756901104\n",
      "Epoch 53600, Loss: 0.010312423180511702\n",
      "Epoch 53700, Loss: 0.010301952601574819\n",
      "Epoch 53800, Loss: 0.010291500964142646\n",
      "Epoch 53900, Loss: 0.010281068212577796\n",
      "Epoch 54000, Loss: 0.01027065429155811\n",
      "Epoch 54100, Loss: 0.010260259146081361\n",
      "Epoch 54200, Loss: 0.010249882721469832\n",
      "Epoch 54300, Loss: 0.0102395249633748\n",
      "Epoch 54400, Loss: 0.010229185817780862\n",
      "Epoch 54500, Loss: 0.010218865231010085\n",
      "Epoch 54600, Loss: 0.010208563149725977\n",
      "Epoch 54700, Loss: 0.010198279520937313\n",
      "Epoch 54800, Loss: 0.0101880142920017\n",
      "Epoch 54900, Loss: 0.010177767410628957\n",
      "Epoch 55000, Loss: 0.010167538824884309\n",
      "Epoch 55100, Loss: 0.010157328483191268\n",
      "Epoch 55200, Loss: 0.01014713633433435\n",
      "Epoch 55300, Loss: 0.010136962327461519\n",
      "Epoch 55400, Loss: 0.01012680641208639\n",
      "Epoch 55500, Loss: 0.010116668538090167\n",
      "Epoch 55600, Loss: 0.010106548655723344\n",
      "Epoch 55700, Loss: 0.010096446715607141\n",
      "Epoch 55800, Loss: 0.010086362668734713\n",
      "Epoch 55900, Loss: 0.010076296466472057\n",
      "Epoch 56000, Loss: 0.010066248060558721\n",
      "Epoch 56100, Loss: 0.010056217403108247\n",
      "Epoch 56200, Loss: 0.010046204446608387\n",
      "Epoch 56300, Loss: 0.01003620914392106\n",
      "Epoch 56400, Loss: 0.010026231448282135\n",
      "Epoch 56500, Loss: 0.010016271313300962\n",
      "Epoch 56600, Loss: 0.010006328692959716\n",
      "Epoch 56700, Loss: 0.00999640354161254\n",
      "Epoch 56800, Loss: 0.009986495813984532\n",
      "Epoch 56900, Loss: 0.009976605465170544\n",
      "Epoch 57000, Loss: 0.009966732450633824\n",
      "Epoch 57100, Loss: 0.009956876726204562\n",
      "Epoch 57200, Loss: 0.009947038248078261\n",
      "Epoch 57300, Loss: 0.009937216972814057\n",
      "Epoch 57400, Loss: 0.009927412857332885\n",
      "Epoch 57500, Loss: 0.009917625858915652\n",
      "Epoch 57600, Loss: 0.00990785593520128\n",
      "Epoch 57700, Loss: 0.009898103044184738\n",
      "Epoch 57800, Loss: 0.009888367144215088\n",
      "Epoch 57900, Loss: 0.009878648193993443\n",
      "Epoch 58000, Loss: 0.009868946152571018\n",
      "Epoch 58100, Loss: 0.009859260979347135\n",
      "Epoch 58200, Loss: 0.009849592634067298\n",
      "Epoch 58300, Loss: 0.009839941076821318\n",
      "Epoch 58400, Loss: 0.009830306268041504\n",
      "Epoch 58500, Loss: 0.00982068816850088\n",
      "Epoch 58600, Loss: 0.009811086739311553\n",
      "Epoch 58700, Loss: 0.009801501941923106\n",
      "Epoch 58800, Loss: 0.00979193373812111\n",
      "Epoch 58900, Loss: 0.009782382090025759\n",
      "Epoch 59000, Loss: 0.009772846960090524\n",
      "Epoch 59100, Loss: 0.009763328311101006\n",
      "Epoch 59200, Loss: 0.009753826106173787\n",
      "Epoch 59300, Loss: 0.009744340308755439\n",
      "Epoch 59400, Loss: 0.00973487088262156\n",
      "Epoch 59500, Loss: 0.00972541779187595\n",
      "Epoch 59600, Loss: 0.00971598100094973\n",
      "Epoch 59700, Loss: 0.009706560474600634\n",
      "Epoch 59800, Loss: 0.009697156177912215\n",
      "Epoch 59900, Loss: 0.00968776807629313\n",
      "Epoch 60000, Loss: 0.009678396135476355\n",
      "Epoch 60100, Loss: 0.009669040321518378\n",
      "Epoch 60200, Loss: 0.00965970060079832\n",
      "Epoch 60300, Loss: 0.009650376940016948\n",
      "Epoch 60400, Loss: 0.009641069306195547\n",
      "Epoch 60500, Loss: 0.009631777666674658\n",
      "Epoch 60600, Loss: 0.009622501989112587\n",
      "Epoch 60700, Loss: 0.009613242241483697\n",
      "Epoch 60800, Loss: 0.009603998392076412\n",
      "Epoch 60900, Loss: 0.009594770409490956\n",
      "Epoch 61000, Loss: 0.009585558262636708\n",
      "Epoch 61100, Loss: 0.009576361920729207\n",
      "Epoch 61200, Loss: 0.009567181353286736\n",
      "Epoch 61300, Loss: 0.009558016530126464\n",
      "Epoch 61400, Loss: 0.009548867421360106\n",
      "Epoch 61500, Loss: 0.009539733997389091\n",
      "Epoch 61600, Loss: 0.009530616228899164\n",
      "Epoch 61700, Loss: 0.009521514086854465\n",
      "Epoch 61800, Loss: 0.009512427542490997\n",
      "Epoch 61900, Loss: 0.00950335656730949\n",
      "Epoch 62000, Loss: 0.009494301133067687\n",
      "Epoch 62100, Loss: 0.009485261211771954\n",
      "Epoch 62200, Loss: 0.009476236775668315\n",
      "Epoch 62300, Loss: 0.009467227797232807\n",
      "Epoch 62400, Loss: 0.009458234249161248\n",
      "Epoch 62500, Loss: 0.009449256104358397\n",
      "Epoch 62600, Loss: 0.009440293335926492\n",
      "Epoch 62700, Loss: 0.00943134591715327\n",
      "Epoch 62800, Loss: 0.0094224138214994\n",
      "Epoch 62900, Loss: 0.009413497022585458\n",
      "Epoch 63000, Loss: 0.009404595494178453\n",
      "Epoch 63100, Loss: 0.00939570921017794\n",
      "Epoch 63200, Loss: 0.009386838144601783\n",
      "Epoch 63300, Loss: 0.009377982271571685\n",
      "Epoch 63400, Loss: 0.009369141565298465\n",
      "Epoch 63500, Loss: 0.009360316000067256\n",
      "Epoch 63600, Loss: 0.009351505550222643\n",
      "Epoch 63700, Loss: 0.00934271019015383\n",
      "Epoch 63800, Loss: 0.00933392989427999\n",
      "Epoch 63900, Loss: 0.009325164637035832\n",
      "Epoch 64000, Loss: 0.009316414392857505\n",
      "Epoch 64100, Loss: 0.009307679136168976\n",
      "Epoch 64200, Loss: 0.009298958841368934\n",
      "Epoch 64300, Loss: 0.00929025348281839\n",
      "Epoch 64400, Loss: 0.009281563034829035\n",
      "Epoch 64500, Loss: 0.009272887471652485\n",
      "Epoch 64600, Loss: 0.009264226767470546\n",
      "Epoch 64700, Loss: 0.009255580896386542\n",
      "Epoch 64800, Loss: 0.009246949832417901\n",
      "Epoch 64900, Loss: 0.00923833354949002\n",
      "Epoch 65000, Loss: 0.009229732021431571\n",
      "Epoch 65100, Loss: 0.00922114522197126\n",
      "Epoch 65200, Loss: 0.009212573124736247\n",
      "Epoch 65300, Loss: 0.009204015703252156\n",
      "Epoch 65400, Loss: 0.009195472930944887\n",
      "Epoch 65500, Loss: 0.009186944781144195\n",
      "Epoch 65600, Loss: 0.00917843122708913\n",
      "Epoch 65700, Loss: 0.009169932241935371\n",
      "Epoch 65800, Loss: 0.009161447798764499\n",
      "Epoch 65900, Loss: 0.00915297787059518\n",
      "Epoch 66000, Loss: 0.009144522430396358\n",
      "Epoch 66100, Loss: 0.00913608145110233\n",
      "Epoch 66200, Loss: 0.0091276549056298\n",
      "Epoch 66300, Loss: 0.0091192427668968\n",
      "Epoch 66400, Loss: 0.009110845007843463\n",
      "Epoch 66500, Loss: 0.009102461601454585\n",
      "Epoch 66600, Loss: 0.009094092520783893\n",
      "Epoch 66700, Loss: 0.009085737738979938\n",
      "Epoch 66800, Loss: 0.009077397229313496\n",
      "Epoch 66900, Loss: 0.009069070965206363\n",
      "Epoch 67000, Loss: 0.00906075892026139\n",
      "Epoch 67100, Loss: 0.00905246106829368\n",
      "Epoch 67200, Loss: 0.009044177383362651\n",
      "Epoch 67300, Loss: 0.009035907839804944\n",
      "Epoch 67400, Loss: 0.009027652412267844\n",
      "Epoch 67500, Loss: 0.009019411075743127\n",
      "Epoch 67600, Loss: 0.009011183805601002\n",
      "Epoch 67700, Loss: 0.009002970577624057\n",
      "Epoch 67800, Loss: 0.008994771368040826\n",
      "Epoch 67900, Loss: 0.008986586153558837\n",
      "Epoch 68000, Loss: 0.00897841491139686\n",
      "Epoch 68100, Loss: 0.008970257619316047\n",
      "Epoch 68200, Loss: 0.008962114255649752\n",
      "Epoch 68300, Loss: 0.008953984799331748\n",
      "Epoch 68400, Loss: 0.008945869229922536\n",
      "Epoch 68500, Loss: 0.00893776752763352\n",
      "Epoch 68600, Loss: 0.008929679673348729\n",
      "Epoch 68700, Loss: 0.008921605648643865\n",
      "Epoch 68800, Loss: 0.00891354543580238\n",
      "Epoch 68900, Loss: 0.008905499017828354\n",
      "Epoch 69000, Loss: 0.008897466378455914\n",
      "Epoch 69100, Loss: 0.00888944750215499\n",
      "Epoch 69200, Loss: 0.008881442374133186\n",
      "Epoch 69300, Loss: 0.008873450980333595\n",
      "Epoch 69400, Loss: 0.008865473307428344\n",
      "Epoch 69500, Loss: 0.008857509342807794\n",
      "Epoch 69600, Loss: 0.008849559074565236\n",
      "Epoch 69700, Loss: 0.008841622491476998\n",
      "Epoch 69800, Loss: 0.008833699582977958\n",
      "Epoch 69900, Loss: 0.008825790339132373\n",
      "Epoch 70000, Loss: 0.008817894750600101\n",
      "Epoch 70100, Loss: 0.008810012808598233\n",
      "Epoch 70200, Loss: 0.008802144504858271\n",
      "Epoch 70300, Loss: 0.008794289831578912\n",
      "Epoch 70400, Loss: 0.0087864487813747\n",
      "Epoch 70500, Loss: 0.008778621347220647\n",
      "Epoch 70600, Loss: 0.008770807522393172\n",
      "Epoch 70700, Loss: 0.008763007300407553\n",
      "Epoch 70800, Loss: 0.008755220674952257\n",
      "Epoch 70900, Loss: 0.008747447639820494\n",
      "Epoch 71000, Loss: 0.008739688188839304\n",
      "Epoch 71100, Loss: 0.008731942315796687\n",
      "Epoch 71200, Loss: 0.008724210014367084\n",
      "Epoch 71300, Loss: 0.008716491278035726\n",
      "Epoch 71400, Loss: 0.008708786100022273\n",
      "Epoch 71500, Loss: 0.008701094473204177\n",
      "Epoch 71600, Loss: 0.008693416390040329\n",
      "Epoch 71700, Loss: 0.008685751842495294\n",
      "Epoch 71800, Loss: 0.008678100821964775\n",
      "Epoch 71900, Loss: 0.008670463319202595\n",
      "Epoch 72000, Loss: 0.008662839324249744\n",
      "Epoch 72100, Loss: 0.008655228826365836\n",
      "Epoch 72200, Loss: 0.00864763181396339\n",
      "Epoch 72300, Loss: 0.00864004827454532\n",
      "Epoch 72400, Loss: 0.008632478194645906\n",
      "Epoch 72500, Loss: 0.008624921559775628\n",
      "Epoch 72600, Loss: 0.008617378354370082\n",
      "Epoch 72700, Loss: 0.008609848561743164\n",
      "Epoch 72800, Loss: 0.008602332164044836\n",
      "Epoch 72900, Loss: 0.008594829142223485\n",
      "Epoch 73000, Loss: 0.008587339475993078\n",
      "Epoch 73100, Loss: 0.008579863143805164\n",
      "Epoch 73200, Loss: 0.008572400122825743\n",
      "Epoch 73300, Loss: 0.008564950388917003\n",
      "Epoch 73400, Loss: 0.00855751391662392\n",
      "Epoch 73500, Loss: 0.00855009067916558\n",
      "Epoch 73600, Loss: 0.008542680648431219\n",
      "Epoch 73700, Loss: 0.00853528379498076\n",
      "Epoch 73800, Loss: 0.00852790008804972\n",
      "Epoch 73900, Loss: 0.008520529495558357\n",
      "Epoch 74000, Loss: 0.00851317198412476\n",
      "Epoch 74100, Loss: 0.008505827519081773\n",
      "Epoch 74200, Loss: 0.008498496064497417\n",
      "Epoch 74300, Loss: 0.008491177583198678\n",
      "Epoch 74400, Loss: 0.008483872036798306\n",
      "Epoch 74500, Loss: 0.008476579385724433\n",
      "Epoch 74600, Loss: 0.008469299589252768\n",
      "Epoch 74700, Loss: 0.008462032605541032\n",
      "Epoch 74800, Loss: 0.008454778391665455\n",
      "Epoch 74900, Loss: 0.00844753690365906\n",
      "Epoch 75000, Loss: 0.00844030809655146\n",
      "Epoch 75100, Loss: 0.008433091924409986\n",
      "Epoch 75200, Loss: 0.008425888340381835\n",
      "Epoch 75300, Loss: 0.008418697296737117\n",
      "Epoch 75400, Loss: 0.008411518744912513\n",
      "Epoch 75500, Loss: 0.008404352635555407\n",
      "Epoch 75600, Loss: 0.008397198918568223\n",
      "Epoch 75700, Loss: 0.008390057543152949\n",
      "Epoch 75800, Loss: 0.008382928457855507\n",
      "Epoch 75900, Loss: 0.008375811610609971\n",
      "Epoch 76000, Loss: 0.008368706948782433\n",
      "Epoch 76100, Loss: 0.008361614419214411\n",
      "Epoch 76200, Loss: 0.008354533968265727\n",
      "Epoch 76300, Loss: 0.008347465541856705\n",
      "Epoch 76400, Loss: 0.008340409085509683\n",
      "Epoch 76500, Loss: 0.008333364544389711\n",
      "Epoch 76600, Loss: 0.008326331863344414\n",
      "Epoch 76700, Loss: 0.008319310986942982\n",
      "Epoch 76800, Loss: 0.008312301859514221\n",
      "Epoch 76900, Loss: 0.00830530442518368\n",
      "Epoch 77000, Loss: 0.008298318627909813\n",
      "Epoch 77100, Loss: 0.008291344411519179\n",
      "Epoch 77200, Loss: 0.008284381719740696\n",
      "Epoch 77300, Loss: 0.008277430496238926\n",
      "Epoch 77400, Loss: 0.008270490684646421\n",
      "Epoch 77500, Loss: 0.008263562228595218\n",
      "Epoch 77600, Loss: 0.008256645071747351\n",
      "Epoch 77700, Loss: 0.008249739157824601\n",
      "Epoch 77800, Loss: 0.008242844430637396\n",
      "Epoch 77900, Loss: 0.008235960834112913\n",
      "Epoch 78000, Loss: 0.008229088312322518\n",
      "Epoch 78100, Loss: 0.008222226809508437\n",
      "Epoch 78200, Loss: 0.008215376270109893\n",
      "Epoch 78300, Loss: 0.008208536638788573\n",
      "Epoch 78400, Loss: 0.008201707860453628\n",
      "Epoch 78500, Loss: 0.008194889880286167\n",
      "Epoch 78600, Loss: 0.008188082643763354\n",
      "Epoch 78700, Loss: 0.008181286096682129\n",
      "Epoch 78800, Loss: 0.008174500185182605\n",
      "Epoch 78900, Loss: 0.008167724855771259\n",
      "Epoch 79000, Loss: 0.008160960055343874\n",
      "Epoch 79100, Loss: 0.008154205731208352\n",
      "Epoch 79200, Loss: 0.008147461831107431\n",
      "Epoch 79300, Loss: 0.00814072830324135\n",
      "Epoch 79400, Loss: 0.008134005096290529\n",
      "Epoch 79500, Loss: 0.008127292159438249\n",
      "Epoch 79600, Loss: 0.00812058944239348\n",
      "Epoch 79700, Loss: 0.008113896895413752\n",
      "Epoch 79800, Loss: 0.008107214469328263\n",
      "Epoch 79900, Loss: 0.008100542115561101\n",
      "Epoch 80000, Loss: 0.008093879786154735\n",
      "Epoch 80100, Loss: 0.00808722743379369\n",
      "Epoch 80200, Loss: 0.008080585011828496\n",
      "Epoch 80300, Loss: 0.008073952474299897\n",
      "Epoch 80400, Loss: 0.008067329775963295\n",
      "Epoch 80500, Loss: 0.008060716872313496\n",
      "Epoch 80600, Loss: 0.00805411371960964\n",
      "Epoch 80700, Loss: 0.008047520274900459\n",
      "Epoch 80800, Loss: 0.008040936496049656\n",
      "Epoch 80900, Loss: 0.008034362341761518\n",
      "Epoch 81000, Loss: 0.008027797771606652\n",
      "Epoch 81100, Loss: 0.00802124274604783\n",
      "Epoch 81200, Loss: 0.008014697226465861\n",
      "Epoch 81300, Loss: 0.008008161175185434\n",
      "Epoch 81400, Loss: 0.008001634555500894\n",
      "Epoch 81500, Loss: 0.007995117331701792\n",
      "Epoch 81600, Loss: 0.007988609469098192\n",
      "Epoch 81700, Loss: 0.007982110934045609\n",
      "Epoch 81800, Loss: 0.007975621693969434\n",
      "Epoch 81900, Loss: 0.007969141717388795\n",
      "Epoch 82000, Loss: 0.00796267097393963\n",
      "Epoch 82100, Loss: 0.007956209434396956\n",
      "Epoch 82200, Loss: 0.007949757070696076\n",
      "Epoch 82300, Loss: 0.00794331385595264\n",
      "Epoch 82400, Loss: 0.007936879764481356\n",
      "Epoch 82500, Loss: 0.007930454771813247\n",
      "Epoch 82600, Loss: 0.00792403885471121\n",
      "Epoch 82700, Loss: 0.007917631991183754\n",
      "Epoch 82800, Loss: 0.007911234160496735\n",
      "Epoch 82900, Loss: 0.007904845343182879\n",
      "Epoch 83000, Loss: 0.00789846552104895\n",
      "Epoch 83100, Loss: 0.007892094677180396\n",
      "Epoch 83200, Loss: 0.007885732795943267\n",
      "Epoch 83300, Loss: 0.00787937986298327\n",
      "Epoch 83400, Loss: 0.007873035865221836\n",
      "Epoch 83500, Loss: 0.007866700790848974\n",
      "Epoch 83600, Loss: 0.007860374629312907\n",
      "Epoch 83700, Loss: 0.007854057371306265\n",
      "Epoch 83800, Loss: 0.007847749008748836\n",
      "Epoch 83900, Loss: 0.007841449534766752\n",
      "Epoch 84000, Loss: 0.00783515894366808\n",
      "Epoch 84100, Loss: 0.00782887723091481\n",
      "Epoch 84200, Loss: 0.007822604393091265\n",
      "Epoch 84300, Loss: 0.007816340427868903\n",
      "Epoch 84400, Loss: 0.007810085333967669\n",
      "Epoch 84500, Loss: 0.007803839111113939\n",
      "Epoch 84600, Loss: 0.007797601759995212\n",
      "Epoch 84700, Loss: 0.007791373282211706\n",
      "Epoch 84800, Loss: 0.00778515368022503\n",
      "Epoch 84900, Loss: 0.007778942957304251\n",
      "Epoch 85000, Loss: 0.007772741117469445\n",
      "Epoch 85100, Loss: 0.007766548165433198\n",
      "Epoch 85200, Loss: 0.007760364106540206\n",
      "Epoch 85300, Loss: 0.007754188946705394\n",
      "Epoch 85400, Loss: 0.007748022692350863\n",
      "Epoch 85500, Loss: 0.007741865350342007\n",
      "Epoch 85600, Loss: 0.007735716927923194\n",
      "Epoch 85700, Loss: 0.007729577432653354\n",
      "Epoch 85800, Loss: 0.007723446872341844\n",
      "Epoch 85900, Loss: 0.007717325254984988\n",
      "Epoch 86000, Loss: 0.0077112125887036035\n",
      "Epoch 86100, Loss: 0.007705108881681867\n",
      "Epoch 86200, Loss: 0.007699014142107889\n",
      "Epoch 86300, Loss: 0.007692928378116216\n",
      "Epoch 86400, Loss: 0.0076868515977326435\n",
      "Epoch 86500, Loss: 0.007680783808821509\n",
      "Epoch 86600, Loss: 0.007674725019035713\n",
      "Epoch 86700, Loss: 0.007668675235769693\n",
      "Epoch 86800, Loss: 0.007662634466115467\n",
      "Epoch 86900, Loss: 0.007656602716821879\n",
      "Epoch 87000, Loss: 0.0076505799942571786\n",
      "Epoch 87100, Loss: 0.007644566304374916\n",
      "Epoch 87200, Loss: 0.007638561652683276\n",
      "Epoch 87300, Loss: 0.007632566044217757\n",
      "Epoch 87400, Loss: 0.007626579483517218\n",
      "Epoch 87500, Loss: 0.007620601974603224\n",
      "Epoch 87600, Loss: 0.007614633520962584\n",
      "Epoch 87700, Loss: 0.007608674125532987\n",
      "Epoch 87800, Loss: 0.007602723790691632\n",
      "Epoch 87900, Loss: 0.00759678251824667\n",
      "Epoch 88000, Loss: 0.007590850309431346\n",
      "Epoch 88100, Loss: 0.007584927164900635\n",
      "Epoch 88200, Loss: 0.007579013084730229\n",
      "Epoch 88300, Loss: 0.007573108068417703\n",
      "Epoch 88400, Loss: 0.007567212114885635\n",
      "Epoch 88500, Loss: 0.007561325222486558\n",
      "Epoch 88600, Loss: 0.007555447389009538\n",
      "Epoch 88700, Loss: 0.007549578611688184\n",
      "Epoch 88800, Loss: 0.007543718887209987\n",
      "Epoch 88900, Loss: 0.0075378682117267235\n",
      "Epoch 89000, Loss: 0.0075320265808658865\n",
      "Epoch 89100, Loss: 0.007526193989742915\n",
      "Epoch 89200, Loss: 0.007520370432974103\n",
      "Epoch 89300, Loss: 0.007514555904690086\n",
      "Epoch 89400, Loss: 0.007508750398549768\n",
      "Epoch 89500, Loss: 0.00750295390775458\n",
      "Epoch 89600, Loss: 0.007497166425062987\n",
      "Epoch 89700, Loss: 0.007491387942805129\n",
      "Epoch 89800, Loss: 0.007485618452897548\n",
      "Epoch 89900, Loss: 0.007479857946857918\n",
      "Epoch 90000, Loss: 0.007474106415819688\n",
      "Epoch 90100, Loss: 0.007468363850546651\n",
      "Epoch 90200, Loss: 0.00746263024144729\n",
      "Epoch 90300, Loss: 0.007456905578588962\n",
      "Epoch 90400, Loss: 0.007451189851711823\n",
      "Epoch 90500, Loss: 0.007445483050242467\n",
      "Epoch 90600, Loss: 0.007439785163307261\n",
      "Epoch 90700, Loss: 0.007434096179745372\n",
      "Epoch 90800, Loss: 0.0074284160881214175\n",
      "Epoch 90900, Loss: 0.007422744876737784\n",
      "Epoch 91000, Loss: 0.007417082533646522\n",
      "Epoch 91100, Loss: 0.00741142904666089\n",
      "Epoch 91200, Loss: 0.007405784403366463\n",
      "Epoch 91300, Loss: 0.007400148591131829\n",
      "Epoch 91400, Loss: 0.0073945215971188746\n",
      "Epoch 91500, Loss: 0.007388903408292609\n",
      "Epoch 91600, Loss: 0.007383294011430556\n",
      "Epoch 91700, Loss: 0.007377693393131681\n",
      "Epoch 91800, Loss: 0.00737210153982487\n",
      "Epoch 91900, Loss: 0.007366518437776898\n",
      "Epoch 92000, Loss: 0.0073609440730999605\n",
      "Epoch 92100, Loss: 0.007355378431758653\n",
      "Epoch 92200, Loss: 0.007349821499576516\n",
      "Epoch 92300, Loss: 0.007344273262241981\n",
      "Epoch 92400, Loss: 0.007338733705313865\n",
      "Epoch 92500, Loss: 0.007333202814226275\n",
      "Epoch 92600, Loss: 0.007327680574292997\n",
      "Epoch 92700, Loss: 0.007322166970711298\n",
      "Epoch 92800, Loss: 0.007316661988565173\n",
      "Epoch 92900, Loss: 0.007311165612828023\n",
      "Epoch 93000, Loss: 0.007305677828364692\n",
      "Epoch 93100, Loss: 0.0073001986199329565\n",
      "Epoch 93200, Loss: 0.00729472797218436\n",
      "Epoch 93300, Loss: 0.007289265869664452\n",
      "Epoch 93400, Loss: 0.007283812296812374\n",
      "Epoch 93500, Loss: 0.007278367237959817\n",
      "Epoch 93600, Loss: 0.007272930677329329\n",
      "Epoch 93700, Loss: 0.007267502599031988\n",
      "Epoch 93800, Loss: 0.007262082987064367\n",
      "Epoch 93900, Loss: 0.0072566718253049035\n",
      "Epoch 94000, Loss: 0.007251269097509557\n",
      "Epoch 94100, Loss: 0.00724587478730683\n",
      "Epoch 94200, Loss: 0.007240488878192124\n",
      "Epoch 94300, Loss: 0.0072351113535214125\n",
      "Epoch 94400, Loss: 0.007229742196504287\n",
      "Epoch 94500, Loss: 0.007224381390196363\n",
      "Epoch 94600, Loss: 0.007219028917491005\n",
      "Epoch 94700, Loss: 0.007213684761110472\n",
      "Epoch 94800, Loss: 0.0072083489035964015\n",
      "Epoch 94900, Loss: 0.007203021327299759\n",
      "Epoch 95000, Loss: 0.007197702014370119\n",
      "Epoch 95100, Loss: 0.007192390946744485\n",
      "Epoch 95200, Loss: 0.00718708810613549\n",
      "Epoch 95300, Loss: 0.007181793474019147\n",
      "Epoch 95400, Loss: 0.007176507031622093\n",
      "Epoch 95500, Loss: 0.007171228759908392\n",
      "Epoch 95600, Loss: 0.007165958639565963\n",
      "Epoch 95700, Loss: 0.007160696650992589\n",
      "Epoch 95800, Loss: 0.007155442774281676\n",
      "Epoch 95900, Loss: 0.007150196989207704\n",
      "Epoch 96000, Loss: 0.007144959275211489\n",
      "Epoch 96100, Loss: 0.007139729611385306\n",
      "Epoch 96200, Loss: 0.0071345079764579475\n",
      "Epoch 96300, Loss: 0.007129294348779772\n",
      "Epoch 96400, Loss: 0.007124088706307873\n",
      "Epoch 96500, Loss: 0.007118891026591431\n",
      "Epoch 96600, Loss: 0.007113701286757372\n",
      "Epoch 96700, Loss: 0.00710851946349645\n",
      "Epoch 96800, Loss: 0.007103345533049871\n",
      "Epoch 96900, Loss: 0.007098179471196647\n",
      "Epoch 97000, Loss: 0.007093021253241797\n",
      "Epoch 97100, Loss: 0.007087870854005609\n",
      "Epoch 97200, Loss: 0.007082728247814163\n",
      "Epoch 97300, Loss: 0.007077593408491331\n",
      "Epoch 97400, Loss: 0.007072466309352506\n",
      "Epoch 97500, Loss: 0.007067346923200369\n",
      "Epoch 97600, Loss: 0.007062235222322935\n",
      "Epoch 97700, Loss: 0.007057131178494308\n",
      "Epoch 97800, Loss: 0.007052034762978436\n",
      "Epoch 97900, Loss: 0.007046945946536319\n",
      "Epoch 98000, Loss: 0.0070418646994371255\n",
      "Epoch 98100, Loss: 0.007036790991473663\n",
      "Epoch 98200, Loss: 0.007031724791982764\n",
      "Epoch 98300, Loss: 0.0070266660698711505\n",
      "Epoch 98400, Loss: 0.00702161479364734\n",
      "Epoch 98500, Loss: 0.0070165709314602715\n",
      "Epoch 98600, Loss: 0.007011534451145278\n",
      "Epoch 98700, Loss: 0.007006505320278099\n",
      "Epoch 98800, Loss: 0.007001483506237606\n",
      "Epoch 98900, Loss: 0.006996468976277938\n",
      "Epoch 99000, Loss: 0.006991461697610651\n",
      "Epoch 99100, Loss: 0.006986461637497518\n",
      "Epoch 99200, Loss: 0.006981468763354483\n",
      "Epoch 99300, Loss: 0.00697648304286713\n",
      "Epoch 99400, Loss: 0.006971504444117947\n",
      "Epoch 99500, Loss: 0.006966532935725375\n",
      "Epoch 99600, Loss: 0.006961568486994411\n",
      "Epoch 99700, Loss: 0.006956611068078226\n",
      "Epoch 99800, Loss: 0.006951660650149805\n",
      "Epoch 99900, Loss: 0.006946717205582303\n",
      "Training complete and model saved!\n",
      "Predicted letter: A\n",
      "Predicted letter: B\n",
      "Predicted letter: O\n",
      "Predicted letter: U\n",
      "Predicted letter: F\n",
      "Predicted letter: F\n",
      "Predicted letter: O\n",
      "Predicted letter: H\n",
      "Predicted letter: I\n",
      "Predicted letter: J\n",
      "Predicted letter: S\n",
      "Predicted letter: Y\n",
      "Predicted letter: F\n",
      "Predicted letter: Y\n",
      "Predicted letter: Y\n",
      "Predicted letter: Q\n",
      "Image saved with label: S\n",
      "Original and augmented images saved for letter 'S'.\n",
      "Predicted letter: W\n",
      "Image saved with label: S\n",
      "Original and augmented images saved for letter 'S'.\n",
      "Predicted letter: P\n",
      "Predicted letter: N\n",
      "Image saved with label: M\n",
      "Original and augmented images saved for letter 'M'.\n",
      "Image saved with label: M\n",
      "Original and augmented images saved for letter 'M'.\n",
      "Image saved with label: M\n",
      "Original and augmented images saved for letter 'M'.\n",
      "Image saved with label: M\n",
      "Original and augmented images saved for letter 'M'.\n",
      "Image saved with label: M\n",
      "Original and augmented images saved for letter 'M'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Predicted letter: W\n",
      "Predicted letter: D\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Image saved with label: D\n",
      "Original and augmented images saved for letter 'D'.\n",
      "Predicted letter: W\n",
      "Predicted letter: V\n",
      "Predicted letter: Z\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Image saved with label: B\n",
      "Original and augmented images saved for letter 'B'.\n",
      "Predicted letter: U\n",
      "Epoch 0, Loss: 0.007492025268289011\n",
      "Epoch 100, Loss: 0.007465611099620206\n",
      "Epoch 200, Loss: 0.007456080282901207\n",
      "Epoch 300, Loss: 0.007447623827120672\n",
      "Epoch 400, Loss: 0.007439596317989232\n",
      "Epoch 500, Loss: 0.00743180565898687\n",
      "Epoch 600, Loss: 0.007424179297107089\n",
      "Epoch 700, Loss: 0.0074166834425775235\n",
      "Epoch 800, Loss: 0.007409299212663599\n",
      "Epoch 900, Loss: 0.007402014366710207\n",
      "Epoch 1000, Loss: 0.007394820038581683\n",
      "Epoch 1100, Loss: 0.007387709292940599\n",
      "Epoch 1200, Loss: 0.007380676421754305\n",
      "Epoch 1300, Loss: 0.007373716569008581\n",
      "Epoch 1400, Loss: 0.007366825512571715\n",
      "Epoch 1500, Loss: 0.007359999526782139\n",
      "Epoch 1600, Loss: 0.007353235289355711\n",
      "Epoch 1700, Loss: 0.007346529814232235\n",
      "Epoch 1800, Loss: 0.007339880400561654\n",
      "Epoch 1900, Loss: 0.007333284592331956\n",
      "Epoch 2000, Loss: 0.007326740145405454\n",
      "Epoch 2100, Loss: 0.007320244999978539\n",
      "Epoch 2200, Loss: 0.00731379725719747\n",
      "Epoch 2300, Loss: 0.007307395159090193\n",
      "Epoch 2400, Loss: 0.0073010370712357385\n",
      "Epoch 2500, Loss: 0.007294721467756093\n",
      "Epoch 2600, Loss: 0.00728844691831854\n",
      "Epoch 2700, Loss: 0.007282212076901863\n",
      "Epoch 2800, Loss: 0.007276015672121794\n",
      "Epoch 2900, Loss: 0.007269856498937949\n",
      "Epoch 3000, Loss: 0.007263733411582978\n",
      "Epoch 3100, Loss: 0.0072576453175674785\n",
      "Epoch 3200, Loss: 0.007251591172624982\n",
      "Epoch 3300, Loss: 0.007245569976470606\n",
      "Epoch 3400, Loss: 0.007239580769256323\n",
      "Epoch 3500, Loss: 0.007233622628615282\n",
      "Epoch 3600, Loss: 0.0072276946671975375\n",
      "Epoch 3700, Loss: 0.007221796030609633\n",
      "Epoch 3800, Loss: 0.007215925895680849\n",
      "Epoch 3900, Loss: 0.0072100834689890125\n",
      "Epoch 4000, Loss: 0.007204267985588601\n",
      "Epoch 4100, Loss: 0.007198478707893068\n",
      "Epoch 4200, Loss: 0.007192714924671954\n",
      "Epoch 4300, Loss: 0.00718697595013083\n",
      "Epoch 4400, Loss: 0.00718126112304921\n",
      "Epoch 4500, Loss: 0.007175569805957209\n",
      "Epoch 4600, Loss: 0.007169901384336855\n",
      "Epoch 4700, Loss: 0.007164255265838124\n",
      "Epoch 4800, Loss: 0.007158630879503043\n",
      "Epoch 4900, Loss: 0.007153027674994029\n",
      "Epoch 5000, Loss: 0.007147445121824554\n",
      "Epoch 5100, Loss: 0.0071418827085918705\n",
      "Epoch 5200, Loss: 0.007136339942212541\n",
      "Epoch 5300, Loss: 0.007130816347162368\n",
      "Epoch 5400, Loss: 0.007125311464722616\n",
      "Epoch 5500, Loss: 0.007119824852234786\n",
      "Epoch 5600, Loss: 0.007114356082366178\n",
      "Epoch 5700, Loss: 0.00710890474238838\n",
      "Epoch 5800, Loss: 0.007103470433470721\n",
      "Epoch 5900, Loss: 0.007098052769990505\n",
      "Epoch 6000, Loss: 0.007092651378861491\n",
      "Epoch 6100, Loss: 0.00708726589888198\n",
      "Epoch 6200, Loss: 0.00708189598010345\n",
      "Epoch 6300, Loss: 0.007076541283220557\n",
      "Epoch 6400, Loss: 0.007071201478982978\n",
      "Epoch 6500, Loss: 0.007065876247629427\n",
      "Epoch 6600, Loss: 0.007060565278343962\n",
      "Epoch 6700, Loss: 0.007055268268734529\n",
      "Epoch 6800, Loss: 0.007049984924333537\n",
      "Epoch 6900, Loss: 0.0070447149581201966\n",
      "Epoch 7000, Loss: 0.007039458090064179\n",
      "Epoch 7100, Loss: 0.0070342140466901435\n",
      "Epoch 7200, Loss: 0.007028982560662576\n",
      "Epoch 7300, Loss: 0.007023763370390394\n",
      "Epoch 7400, Loss: 0.00701855621965068\n",
      "Epoch 7500, Loss: 0.0070133608572309466\n",
      "Epoch 7600, Loss: 0.007008177036589337\n",
      "Epoch 7700, Loss: 0.0070030045155320955\n",
      "Epoch 7800, Loss: 0.0069978430559077785\n",
      "Epoch 7900, Loss: 0.006992692423317578\n",
      "Epoch 8000, Loss: 0.006987552386841221\n",
      "Epoch 8100, Loss: 0.006982422718777975\n",
      "Epoch 8200, Loss: 0.006977303194402205\n",
      "Epoch 8300, Loss: 0.006972193591733109\n",
      "Epoch 8400, Loss: 0.00696709369131819\n",
      "Epoch 8500, Loss: 0.006962003276030147\n",
      "Epoch 8600, Loss: 0.00695692213087684\n",
      "Epoch 8700, Loss: 0.006951850042824096\n",
      "Epoch 8800, Loss: 0.0069467868006311394\n",
      "Epoch 8900, Loss: 0.006941732194698499\n",
      "Epoch 9000, Loss: 0.00693668601692822\n",
      "Epoch 9100, Loss: 0.00693164806059644\n",
      "Epoch 9200, Loss: 0.006926618120238191\n",
      "Epoch 9300, Loss: 0.00692159599154453\n",
      "Epoch 9400, Loss: 0.006916581471272127\n",
      "Epoch 9500, Loss: 0.006911574357165363\n",
      "Epoch 9600, Loss: 0.006906574447891202\n",
      "Epoch 9700, Loss: 0.006901581542986998\n",
      "Epoch 9800, Loss: 0.006896595442821586\n",
      "Epoch 9900, Loss: 0.006891615948569908\n",
      "Epoch 10000, Loss: 0.006886642862201544\n",
      "Epoch 10100, Loss: 0.006881675986483528\n",
      "Epoch 10200, Loss: 0.006876715124997829\n",
      "Epoch 10300, Loss: 0.006871760082173944\n",
      "Epoch 10400, Loss: 0.006866810663336988\n",
      "Epoch 10500, Loss: 0.006861866674771748\n",
      "Epoch 10600, Loss: 0.006856927923803068\n",
      "Epoch 10700, Loss: 0.006851994218893017\n",
      "Epoch 10800, Loss: 0.006847065369755123\n",
      "Epoch 10900, Loss: 0.006842141187486044\n",
      "Epoch 11000, Loss: 0.006837221484714913\n",
      "Epoch 11100, Loss: 0.006832306075770449\n",
      "Epoch 11200, Loss: 0.00682739477686604\n",
      "Epoch 11300, Loss: 0.006822487406302601\n",
      "Epoch 11400, Loss: 0.006817583784689139\n",
      "Epoch 11500, Loss: 0.006812683735180658\n",
      "Epoch 11600, Loss: 0.00680778708373288\n",
      "Epoch 11700, Loss: 0.006802893659373148\n",
      "Epoch 11800, Loss: 0.00679800329448659\n",
      "Epoch 11900, Loss: 0.0067931158251164515\n",
      "Epoch 12000, Loss: 0.006788231091277266\n",
      "Epoch 12100, Loss: 0.006783348937279304\n",
      "Epoch 12200, Loss: 0.006778469212062467\n",
      "Epoch 12300, Loss: 0.006773591769537591\n",
      "Epoch 12400, Loss: 0.006768716468932853\n",
      "Epoch 12500, Loss: 0.006763843175142786\n",
      "Epoch 12600, Loss: 0.006758971759077099\n",
      "Epoch 12700, Loss: 0.006754102098006452\n",
      "Epoch 12800, Loss: 0.006749234075902017\n",
      "Epoch 12900, Loss: 0.006744367583765653\n",
      "Epoch 13000, Loss: 0.006739502519947353\n",
      "Epoch 13100, Loss: 0.006734638790446614\n",
      "Epoch 13200, Loss: 0.006729776309194383\n",
      "Epoch 13300, Loss: 0.00672491499831232\n",
      "Epoch 13400, Loss: 0.006720054788346164\n",
      "Epoch 13500, Loss: 0.0067151956184703186\n",
      "Epoch 13600, Loss: 0.006710337436660846\n",
      "Epoch 13700, Loss: 0.006705480199834455\n",
      "Epoch 13800, Loss: 0.006700623873951456\n",
      "Epoch 13900, Loss: 0.006695768434080913\n",
      "Epoch 14000, Loss: 0.006690913864426814\n",
      "Epoch 14100, Loss: 0.006686060158314428\n",
      "Epoch 14200, Loss: 0.006681207318136592\n",
      "Epoch 14300, Loss: 0.00667635535526009\n",
      "Epoch 14400, Loss: 0.0066715042898928085\n",
      "Epoch 14500, Loss: 0.00666665415091287\n",
      "Epoch 14600, Loss: 0.006661804975661255\n",
      "Epoch 14700, Loss: 0.0066569568097000435\n",
      "Epoch 14800, Loss: 0.0066521097065385506\n",
      "Epoch 14900, Loss: 0.006647263727330098\n",
      "Epoch 15000, Loss: 0.0066424189405423625\n",
      "Epoch 15100, Loss: 0.006637575421604422\n",
      "Epoch 15200, Loss: 0.006632733252533761\n",
      "Epoch 15300, Loss: 0.0066278925215465904\n",
      "Epoch 15400, Loss: 0.006623053322654835\n",
      "Epoch 15500, Loss: 0.006618215755253058\n",
      "Epoch 15600, Loss: 0.006613379923698602\n",
      "Epoch 15700, Loss: 0.006608545936888018\n",
      "Epoch 15800, Loss: 0.006603713907832725\n",
      "Epoch 15900, Loss: 0.006598883953236715\n",
      "Epoch 16000, Loss: 0.00659405619307882\n",
      "Epoch 16100, Loss: 0.006589230750201996\n",
      "Epoch 16200, Loss: 0.00658440774991173\n",
      "Epoch 16300, Loss: 0.006579587319585647\n",
      "Epoch 16400, Loss: 0.0065747695882960085\n",
      "Epoch 16500, Loss: 0.006569954686446805\n",
      "Epoch 16600, Loss: 0.0065651427454268396\n",
      "Epoch 16700, Loss: 0.006560333897280093\n",
      "Epoch 16800, Loss: 0.006555528274394529\n",
      "Epoch 16900, Loss: 0.006550726009210308\n",
      "Epoch 17000, Loss: 0.00654592723394827\n",
      "Epoch 17100, Loss: 0.006541132080359427\n",
      "Epoch 17200, Loss: 0.006536340679496051\n",
      "Epoch 17300, Loss: 0.006531553161504794\n",
      "Epoch 17400, Loss: 0.006526769655442188\n",
      "Epoch 17500, Loss: 0.006521990289112697\n",
      "Epoch 17600, Loss: 0.006517215188929317\n",
      "Epoch 17700, Loss: 0.006512444479796656\n",
      "Epoch 17800, Loss: 0.006507678285016148\n",
      "Epoch 17900, Loss: 0.006502916726213007\n",
      "Epoch 18000, Loss: 0.006498159923284253\n",
      "Epoch 18100, Loss: 0.006493407994367078\n",
      "Epoch 18200, Loss: 0.006488661055826571\n",
      "Epoch 18300, Loss: 0.006483919222261734\n",
      "Epoch 18400, Loss: 0.0064791826065285175\n",
      "Epoch 18500, Loss: 0.006474451319778491\n",
      "Epoch 18600, Loss: 0.00646972547151164\n",
      "Epoch 18700, Loss: 0.006465005169641692\n",
      "Epoch 18800, Loss: 0.006460290520572217\n",
      "Epoch 18900, Loss: 0.0064555816292817545\n",
      "Epoch 19000, Loss: 0.00645087859941615\n",
      "Epoch 19100, Loss: 0.006446181533386227\n",
      "Epoch 19200, Loss: 0.006441490532468934\n",
      "Epoch 19300, Loss: 0.006436805696910146\n",
      "Epoch 19400, Loss: 0.006432127126027333\n",
      "Epoch 19500, Loss: 0.006427454918310301\n",
      "Epoch 19600, Loss: 0.006422789171518443\n",
      "Epoch 19700, Loss: 0.006418129982772823\n",
      "Epoch 19800, Loss: 0.006413477448641794\n",
      "Epoch 19900, Loss: 0.006408831665218693\n",
      "Epoch 20000, Loss: 0.006404192728190561\n",
      "Epoch 20100, Loss: 0.006399560732896803\n",
      "Epoch 20200, Loss: 0.006394935774376931\n",
      "Epoch 20300, Loss: 0.006390317947406763\n",
      "Epoch 20400, Loss: 0.006385707346522462\n",
      "Epoch 20500, Loss: 0.006381104066032124\n",
      "Epoch 20600, Loss: 0.006376508200014714\n",
      "Epoch 20700, Loss: 0.0063719198423063126\n",
      "Epoch 20800, Loss: 0.006367339086473823\n",
      "Epoch 20900, Loss: 0.0063627660257764155\n",
      "Epoch 21000, Loss: 0.006358200753115167\n",
      "Epoch 21100, Loss: 0.006353643360971406\n",
      "Epoch 21200, Loss: 0.006349093941334515\n",
      "Epoch 21300, Loss: 0.006344552585619908\n",
      "Epoch 21400, Loss: 0.006340019384578128\n",
      "Epoch 21500, Loss: 0.006335494428195999\n",
      "Epoch 21600, Loss: 0.006330977805590878\n",
      "Epoch 21700, Loss: 0.006326469604899063\n",
      "Epoch 21800, Loss: 0.006321969913159539\n",
      "Epoch 21900, Loss: 0.006317478816194108\n",
      "Epoch 22000, Loss: 0.006312996398485137\n",
      "Epoch 22100, Loss: 0.006308522743052019\n",
      "Epoch 22200, Loss: 0.006304057931327495\n",
      "Epoch 22300, Loss: 0.006299602043034904\n",
      "Epoch 22400, Loss: 0.0062951551560674395\n",
      "Epoch 22500, Loss: 0.006290717346370391\n",
      "Epoch 22600, Loss: 0.006286288687827336\n",
      "Epoch 22700, Loss: 0.006281869252151132\n",
      "Epoch 22800, Loss: 0.00627745910878049\n",
      "Epoch 22900, Loss: 0.006273058324782922\n",
      "Epoch 23000, Loss: 0.006268666964764607\n",
      "Epoch 23100, Loss: 0.006264285090787773\n",
      "Epoch 23200, Loss: 0.0062599127622960755\n",
      "Epoch 23300, Loss: 0.00625555003604827\n",
      "Epoch 23400, Loss: 0.006251196966060563\n",
      "Epoch 23500, Loss: 0.006246853603557763\n",
      "Epoch 23600, Loss: 0.006242519996933393\n",
      "Epoch 23700, Loss: 0.0062381961917187785\n",
      "Epoch 23800, Loss: 0.006233882230561072\n",
      "Epoch 23900, Loss: 0.006229578153210128\n",
      "Epoch 24000, Loss: 0.006225283996514019\n",
      "Epoch 24100, Loss: 0.006220999794422966\n",
      "Epoch 24200, Loss: 0.006216725578001404\n",
      "Epoch 24300, Loss: 0.006212461375447815\n",
      "Epoch 24400, Loss: 0.006208207212121955\n",
      "Epoch 24500, Loss: 0.006203963110579076\n",
      "Epoch 24600, Loss: 0.006199729090610642\n",
      "Epoch 24700, Loss: 0.006195505169291104\n",
      "Epoch 24800, Loss: 0.006191291361030248\n",
      "Epoch 24900, Loss: 0.006187087677630541\n",
      "Epoch 25000, Loss: 0.006182894128349072\n",
      "Epoch 25100, Loss: 0.006178710719963453\n",
      "Epoch 25200, Loss: 0.006174537456841269\n",
      "Epoch 25300, Loss: 0.006170374341012505\n",
      "Epoch 25400, Loss: 0.006166221372244491\n",
      "Epoch 25500, Loss: 0.006162078548118863\n",
      "Epoch 25600, Loss: 0.006157945864110097\n",
      "Epoch 25700, Loss: 0.006153823313665156\n",
      "Epoch 25800, Loss: 0.006149710888283843\n",
      "Epoch 25900, Loss: 0.006145608577599467\n",
      "Epoch 26000, Loss: 0.006141516369459411\n",
      "Epoch 26100, Loss: 0.006137434250005328\n",
      "Epoch 26200, Loss: 0.006133362203752608\n",
      "Epoch 26300, Loss: 0.0061293002136687995\n",
      "Epoch 26400, Loss: 0.006125248261250778\n",
      "Epoch 26500, Loss: 0.006121206326600424\n",
      "Epoch 26600, Loss: 0.006117174388498548\n",
      "Epoch 26700, Loss: 0.006113152424476963\n",
      "Epoch 26800, Loss: 0.00610914041088849\n",
      "Epoch 26900, Loss: 0.006105138322974799\n",
      "Epoch 27000, Loss: 0.006101146134931982\n",
      "Epoch 27100, Loss: 0.006097163819973771\n",
      "Epoch 27200, Loss: 0.00609319135039234\n",
      "Epoch 27300, Loss: 0.006089228697616653\n",
      "Epoch 27400, Loss: 0.006085275832268366\n",
      "Epoch 27500, Loss: 0.006081332724215235\n",
      "Epoch 27600, Loss: 0.006077399342622073\n",
      "Epoch 27700, Loss: 0.0060734756559993\n",
      "Epoch 27800, Loss: 0.006069561632249088\n",
      "Epoch 27900, Loss: 0.006065657238709173\n",
      "Epoch 28000, Loss: 0.006061762442194443\n",
      "Epoch 28100, Loss: 0.006057877209036266\n",
      "Epoch 28200, Loss: 0.006054001505119787\n",
      "Epoch 28300, Loss: 0.006050135295919124\n",
      "Epoch 28400, Loss: 0.006046278546530692\n",
      "Epoch 28500, Loss: 0.00604243122170466\n",
      "Epoch 28600, Loss: 0.006038593285874687\n",
      "Epoch 28700, Loss: 0.006034764703186\n",
      "Epoch 28800, Loss: 0.006030945437521966\n",
      "Epoch 28900, Loss: 0.00602713545252921\n",
      "Epoch 29000, Loss: 0.006023334711641405\n",
      "Epoch 29100, Loss: 0.006019543178101826\n",
      "Epoch 29200, Loss: 0.006015760814984754\n",
      "Epoch 29300, Loss: 0.006011987585215853\n",
      "Epoch 29400, Loss: 0.00600822345159157\n",
      "Epoch 29500, Loss: 0.00600446837679767\n",
      "Epoch 29600, Loss: 0.006000722323426965\n",
      "Epoch 29700, Loss: 0.005996985253996365\n",
      "Epoch 29800, Loss: 0.005993257130963229\n",
      "Epoch 29900, Loss: 0.005989537916741163\n",
      "Epoch 30000, Loss: 0.005985827573715333\n",
      "Epoch 30100, Loss: 0.005982126064257254\n",
      "Epoch 30200, Loss: 0.005978433350739191\n",
      "Epoch 30300, Loss: 0.005974749395548223\n",
      "Epoch 30400, Loss: 0.005971074161099943\n",
      "Epoch 30500, Loss: 0.005967407609851868\n",
      "Epoch 30600, Loss: 0.005963749704316604\n",
      "Epoch 30700, Loss: 0.005960100407074778\n",
      "Epoch 30800, Loss: 0.005956459680787722\n",
      "Epoch 30900, Loss: 0.005952827488209991\n",
      "Epoch 31000, Loss: 0.005949203792201676\n",
      "Epoch 31100, Loss: 0.005945588555740561\n",
      "Epoch 31200, Loss: 0.00594198174193407\n",
      "Epoch 31300, Loss: 0.005938383314031078\n",
      "Epoch 31400, Loss: 0.00593479323543354\n",
      "Epoch 31500, Loss: 0.005931211469707921\n",
      "Epoch 31600, Loss: 0.0059276379805964985\n",
      "Epoch 31700, Loss: 0.005924072732028417\n",
      "Epoch 31800, Loss: 0.005920515688130569\n",
      "Epoch 31900, Loss: 0.005916966813238272\n",
      "Epoch 32000, Loss: 0.00591342607190568\n",
      "Epoch 32100, Loss: 0.005909893428916011\n",
      "Epoch 32200, Loss: 0.005906368849291455\n",
      "Epoch 32300, Loss: 0.00590285229830285\n",
      "Epoch 32400, Loss: 0.00589934374147904\n",
      "Epoch 32500, Loss: 0.005895843144615922\n",
      "Epoch 32600, Loss: 0.00589235047378518\n",
      "Epoch 32700, Loss: 0.005888865695342632\n",
      "Epoch 32800, Loss: 0.005885388775936247\n",
      "Epoch 32900, Loss: 0.005881919682513734\n",
      "Epoch 33000, Loss: 0.005878458382329743\n",
      "Epoch 33100, Loss: 0.00587500484295262\n",
      "Epoch 33200, Loss: 0.005871559032270734\n",
      "Epoch 33300, Loss: 0.005868120918498321\n",
      "Epoch 33400, Loss: 0.005864690470180824\n",
      "Epoch 33500, Loss: 0.0058612676561997775\n",
      "Epoch 33600, Loss: 0.0058578524457771185\n",
      "Epoch 33700, Loss: 0.005854444808479005\n",
      "Epoch 33800, Loss: 0.005851044714219044\n",
      "Epoch 33900, Loss: 0.005847652133260989\n",
      "Epoch 34000, Loss: 0.005844267036220828\n",
      "Epoch 34100, Loss: 0.005840889394068306\n",
      "Epoch 34200, Loss: 0.00583751917812783\n",
      "Epoch 34300, Loss: 0.005834156360078772\n",
      "Epoch 34400, Loss: 0.005830800911955149\n",
      "Epoch 34500, Loss: 0.005827452806144687\n",
      "Epoch 34600, Loss: 0.005824112015387261\n",
      "Epoch 34700, Loss: 0.005820778512772673\n",
      "Epoch 34800, Loss: 0.005817452271737865\n",
      "Epoch 34900, Loss: 0.005814133266063437\n",
      "Epoch 35000, Loss: 0.005810821469869573\n",
      "Epoch 35100, Loss: 0.005807516857611369\n",
      "Epoch 35200, Loss: 0.005804219404073499\n",
      "Epoch 35300, Loss: 0.00580092908436433\n",
      "Epoch 35400, Loss: 0.005797645873909436\n",
      "Epoch 35500, Loss: 0.005794369748444533\n",
      "Epoch 35600, Loss: 0.005791100684007874\n",
      "Epoch 35700, Loss: 0.005787838656932109\n",
      "Epoch 35800, Loss: 0.005784583643835635\n",
      "Epoch 35900, Loss: 0.005781335621613462\n",
      "Epoch 36000, Loss: 0.005778094567427629\n",
      "Epoch 36100, Loss: 0.005774860458697177\n",
      "Epoch 36200, Loss: 0.005771633273087744\n",
      "Epoch 36300, Loss: 0.005768412988500792\n",
      "Epoch 36400, Loss: 0.005765199583062497\n",
      "Epoch 36500, Loss: 0.005761993035112368\n",
      "Epoch 36600, Loss: 0.005758793323191594\n",
      "Epoch 36700, Loss: 0.005755600426031188\n",
      "Epoch 36800, Loss: 0.0057524143225399565\n",
      "Epoch 36900, Loss: 0.005749234991792334\n",
      "Epoch 37000, Loss: 0.005746062413016131\n",
      "Epoch 37100, Loss: 0.005742896565580231\n",
      "Epoch 37200, Loss: 0.0057397374289822655\n",
      "Epoch 37300, Loss: 0.0057365849828363465\n",
      "Epoch 37400, Loss: 0.005733439206860852\n",
      "Epoch 37500, Loss: 0.005730300080866322\n",
      "Epoch 37600, Loss: 0.00572716758474352\n",
      "Epoch 37700, Loss: 0.00572404169845167\n",
      "Epoch 37800, Loss: 0.005720922402006908\n",
      "Epoch 37900, Loss: 0.005717809675471012\n",
      "Epoch 38000, Loss: 0.005714703498940385\n",
      "Epoch 38100, Loss: 0.005711603852535397\n",
      "Epoch 38200, Loss: 0.0057085107163900245\n",
      "Epoch 38300, Loss: 0.005705424070641878\n",
      "Epoch 38400, Loss: 0.005702343895422627\n",
      "Epoch 38500, Loss: 0.005699270170848818\n",
      "Epoch 38600, Loss: 0.00569620287701312\n",
      "Epoch 38700, Loss: 0.005693141993976013\n",
      "Epoch 38800, Loss: 0.00569008750175793\n",
      "Epoch 38900, Loss: 0.00568703938033183\n",
      "Epoch 39000, Loss: 0.005683997609616281\n",
      "Epoch 39100, Loss: 0.005680962169468982\n",
      "Epoch 39200, Loss: 0.005677933039680745\n",
      "Epoch 39300, Loss: 0.005674910199969981\n",
      "Epoch 39400, Loss: 0.005671893629977611\n",
      "Epoch 39500, Loss: 0.005668883309262477\n",
      "Epoch 39600, Loss: 0.005665879217297154\n",
      "Epoch 39700, Loss: 0.005662881333464276\n",
      "Epoch 39800, Loss: 0.005659889637053211\n",
      "Epoch 39900, Loss: 0.005656904107257234\n",
      "Epoch 40000, Loss: 0.005653924723171054\n",
      "Epoch 40100, Loss: 0.005650951463788752\n",
      "Epoch 40200, Loss: 0.005647984308002114\n",
      "Epoch 40300, Loss: 0.005645023234599284\n",
      "Epoch 40400, Loss: 0.005642068222263797\n",
      "Epoch 40500, Loss: 0.00563911924957392\n",
      "Epoch 40600, Loss: 0.005636176295002309\n",
      "Epoch 40700, Loss: 0.005633239336915945\n",
      "Epoch 40800, Loss: 0.00563030835357636\n",
      "Epoch 40900, Loss: 0.005627383323140102\n",
      "Epoch 41000, Loss: 0.005624464223659425\n",
      "Epoch 41100, Loss: 0.005621551033083229\n",
      "Epoch 41200, Loss: 0.005618643729258171\n",
      "Epoch 41300, Loss: 0.00561574228992996\n",
      "Epoch 41400, Loss: 0.005612846692744831\n",
      "Epoch 41500, Loss: 0.005609956915251146\n",
      "Epoch 41600, Loss: 0.00560707293490116\n",
      "Epoch 41700, Loss: 0.005604194729052848\n",
      "Epoch 41800, Loss: 0.005601322274971905\n",
      "Epoch 41900, Loss: 0.005598455549833756\n",
      "Epoch 42000, Loss: 0.005595594530725704\n",
      "Epoch 42100, Loss: 0.005592739194649085\n",
      "Epoch 42200, Loss: 0.005589889518521526\n",
      "Epoch 42300, Loss: 0.0055870454791791665\n",
      "Epoch 42400, Loss: 0.005584207053378979\n",
      "Epoch 42500, Loss: 0.0055813742178010585\n",
      "Epoch 42600, Loss: 0.0055785469490509014\n",
      "Epoch 42700, Loss: 0.005575725223661734\n",
      "Epoch 42800, Loss: 0.005572909018096779\n",
      "Epoch 42900, Loss: 0.005570098308751515\n",
      "Epoch 43000, Loss: 0.005567293071955913\n",
      "Epoch 43100, Loss: 0.0055644932839766185\n",
      "Epoch 43200, Loss: 0.00556169892101912\n",
      "Epoch 43300, Loss: 0.005558909959229836\n",
      "Epoch 43400, Loss: 0.005556126374698181\n",
      "Epoch 43500, Loss: 0.005553348143458533\n",
      "Epoch 43600, Loss: 0.005550575241492201\n",
      "Epoch 43700, Loss: 0.005547807644729245\n",
      "Epoch 43800, Loss: 0.005545045329050308\n",
      "Epoch 43900, Loss: 0.005542288270288328\n",
      "Epoch 44000, Loss: 0.005539536444230187\n",
      "Epoch 44100, Loss: 0.0055367898266183\n",
      "Epoch 44200, Loss: 0.005534048393152104\n",
      "Epoch 44300, Loss: 0.00553131211948949\n",
      "Epoch 44400, Loss: 0.00552858098124816\n",
      "Epoch 44500, Loss: 0.005525854954006879\n",
      "Epoch 44600, Loss: 0.005523134013306685\n",
      "Epoch 44700, Loss: 0.005520418134652003\n",
      "Epoch 44800, Loss: 0.005517707293511694\n",
      "Epoch 44900, Loss: 0.00551500146532002\n",
      "Epoch 45000, Loss: 0.005512300625477548\n",
      "Epoch 45100, Loss: 0.005509604749351991\n",
      "Epoch 45200, Loss: 0.005506913812278964\n",
      "Epoch 45300, Loss: 0.0055042277895626995\n",
      "Epoch 45400, Loss: 0.005501546656476681\n",
      "Epoch 45500, Loss: 0.005498870388264253\n",
      "Epoch 45600, Loss: 0.00549619896013915\n",
      "Epoch 45700, Loss: 0.005493532347286\n",
      "Epoch 45800, Loss: 0.0054908705248607765\n",
      "Epoch 45900, Loss: 0.005488213467991225\n",
      "Epoch 46000, Loss: 0.005485561151777257\n",
      "Epoch 46100, Loss: 0.005482913551291329\n",
      "Epoch 46200, Loss: 0.005480270641578789\n",
      "Epoch 46300, Loss: 0.005477632397658238\n",
      "Epoch 46400, Loss: 0.005474998794521889\n",
      "Epoch 46500, Loss: 0.005472369807135934\n",
      "Epoch 46600, Loss: 0.005469745410440921\n",
      "Epoch 46700, Loss: 0.005467125579352174\n",
      "Epoch 46800, Loss: 0.0054645102887602584\n",
      "Epoch 46900, Loss: 0.0054618995135314935\n",
      "Epoch 47000, Loss: 0.005459293228508508\n",
      "Epoch 47100, Loss: 0.005456691408510922\n",
      "Epoch 47200, Loss: 0.005454094028336065\n",
      "Epoch 47300, Loss: 0.005451501062759848\n",
      "Epoch 47400, Loss: 0.00544891248653771\n",
      "Epoch 47500, Loss: 0.0054463282744057545\n",
      "Epoch 47600, Loss: 0.0054437484010819845\n",
      "Epoch 47700, Loss: 0.005441172841267754\n",
      "Epoch 47800, Loss: 0.005438601569649394\n",
      "Epoch 47900, Loss: 0.005436034560900037\n",
      "Epoch 48000, Loss: 0.005433471789681695\n",
      "Epoch 48100, Loss: 0.005430913230647591\n",
      "Epoch 48200, Loss: 0.005428358858444753\n",
      "Epoch 48300, Loss: 0.005425808647716919\n",
      "Epoch 48400, Loss: 0.005423262573107782\n",
      "Epoch 48500, Loss: 0.005420720609264563\n",
      "Epoch 48600, Loss: 0.005418182730842\n",
      "Epoch 48700, Loss: 0.005415648912506722\n",
      "Epoch 48800, Loss: 0.005413119128942076\n",
      "Epoch 48900, Loss: 0.005410593354853431\n",
      "Epoch 49000, Loss: 0.005408071564973974\n",
      "Epoch 49100, Loss: 0.005405553734071068\n",
      "Epoch 49200, Loss: 0.005403039836953151\n",
      "Epoch 49300, Loss: 0.005400529848477268\n",
      "Epoch 49400, Loss: 0.005398023743557241\n",
      "Epoch 49500, Loss: 0.005395521497172508\n",
      "Epoch 49600, Loss: 0.0053930230843776674\n",
      "Epoch 49700, Loss: 0.005390528480312815\n",
      "Epoch 49800, Loss: 0.005388037660214622\n",
      "Epoch 49900, Loss: 0.005385550599428247\n",
      "Epoch 50000, Loss: 0.00538306727342013\n",
      "Epoch 50100, Loss: 0.005380587657791638\n",
      "Epoch 50200, Loss: 0.005378111728293663\n",
      "Epoch 50300, Loss: 0.005375639460842153\n",
      "Epoch 50400, Loss: 0.005373170831534648\n",
      "Epoch 50500, Loss: 0.0053707058166677845\n",
      "Epoch 50600, Loss: 0.005368244392755859\n",
      "Epoch 50700, Loss: 0.005365786536550428\n",
      "Epoch 50800, Loss: 0.005363332225060949\n",
      "Epoch 50900, Loss: 0.0053608814355765\n",
      "Epoch 51000, Loss: 0.005358434145688574\n",
      "Epoch 51100, Loss: 0.005355990333314887\n",
      "Epoch 51200, Loss: 0.005353549976724294\n",
      "Epoch 51300, Loss: 0.00535111305456269\n",
      "Epoch 51400, Loss: 0.005348679545879899\n",
      "Epoch 51500, Loss: 0.005346249430157557\n",
      "Epoch 51600, Loss: 0.005343822687337838\n",
      "Epoch 51700, Loss: 0.005341399297853085\n",
      "Epoch 51800, Loss: 0.005338979242656144\n",
      "Epoch 51900, Loss: 0.005336562503251429\n",
      "Epoch 52000, Loss: 0.0053341490617265196\n",
      "Epoch 52100, Loss: 0.005331738900784256\n",
      "Epoch 52200, Loss: 0.005329332003775153\n",
      "Epoch 52300, Loss: 0.005326928354730002\n",
      "Epoch 52400, Loss: 0.0053245279383925285\n",
      "Epoch 52500, Loss: 0.005322130740251894\n",
      "Epoch 52600, Loss: 0.005319736746574897\n",
      "Epoch 52700, Loss: 0.005317345944437643\n",
      "Epoch 52800, Loss: 0.005314958321756496\n",
      "Epoch 52900, Loss: 0.005312573867318081\n",
      "Epoch 53000, Loss: 0.005310192570808091\n",
      "Epoch 53100, Loss: 0.005307814422838696\n",
      "Epoch 53200, Loss: 0.005305439414974266\n",
      "Epoch 53300, Loss: 0.005303067539755147\n",
      "Epoch 53400, Loss: 0.005300698790719305\n",
      "Epoch 53500, Loss: 0.0052983331624214995\n",
      "Epoch 53600, Loss: 0.005295970650449762\n",
      "Epoch 53700, Loss: 0.005293611251438961\n",
      "Epoch 53800, Loss: 0.00529125496308116\n",
      "Epoch 53900, Loss: 0.005288901784132594\n",
      "Epoch 54000, Loss: 0.005286551714417009\n",
      "Epoch 54100, Loss: 0.005284204754825184\n",
      "Epoch 54200, Loss: 0.005281860907310498\n",
      "Epoch 54300, Loss: 0.0052795201748803144\n",
      "Epoch 54400, Loss: 0.005277182561583173\n",
      "Epoch 54500, Loss: 0.005274848072491584\n",
      "Epoch 54600, Loss: 0.005272516713680459\n",
      "Epoch 54700, Loss: 0.005270188492201125\n",
      "Epoch 54800, Loss: 0.005267863416050942\n",
      "Epoch 54900, Loss: 0.005265541494138562\n",
      "Epoch 55000, Loss: 0.005263222736244979\n",
      "Epoch 55100, Loss: 0.0052609071529804395\n",
      "Epoch 55200, Loss: 0.005258594755737461\n",
      "Epoch 55300, Loss: 0.005256285556640089\n",
      "Epoch 55400, Loss: 0.005253979568489736\n",
      "Epoch 55500, Loss: 0.0052516768047078085\n",
      "Epoch 55600, Loss: 0.005249377279275496\n",
      "Epoch 55700, Loss: 0.005247081006671041\n",
      "Epoch 55800, Loss: 0.0052447880018048725\n",
      "Epoch 55900, Loss: 0.005242498279952986\n",
      "Epoch 56000, Loss: 0.0052402118566890225\n",
      "Epoch 56100, Loss: 0.0052379287478153775\n",
      "Epoch 56200, Loss: 0.005235648969293906\n",
      "Epoch 56300, Loss: 0.005233372537176505\n",
      "Epoch 56400, Loss: 0.00523109946753613\n",
      "Epoch 56500, Loss: 0.005228829776398582\n",
      "Epoch 56600, Loss: 0.005226563479675519\n",
      "Epoch 56700, Loss: 0.005224300593099047\n",
      "Epoch 56800, Loss: 0.005222041132158319\n",
      "Epoch 56900, Loss: 0.005219785112038398\n",
      "Epoch 57000, Loss: 0.005217532547561788\n",
      "Epoch 57100, Loss: 0.005215283453132853\n",
      "Epoch 57200, Loss: 0.005213037842685422\n",
      "Epoch 57300, Loss: 0.005210795729633748\n",
      "Epoch 57400, Loss: 0.005208557126827055\n",
      "Epoch 57500, Loss: 0.005206322046507766\n",
      "Epoch 57600, Loss: 0.0052040905002735255\n",
      "Epoch 57700, Loss: 0.005201862499043146\n",
      "Epoch 57800, Loss: 0.005199638053026407\n",
      "Epoch 57900, Loss: 0.005197417171697805\n",
      "Epoch 58000, Loss: 0.005195199863774135\n",
      "Epoch 58100, Loss: 0.005192986137195947\n",
      "Epoch 58200, Loss: 0.0051907759991126675\n",
      "Epoch 58300, Loss: 0.005188569455871366\n",
      "Epoch 58400, Loss: 0.005186366513008986\n",
      "Epoch 58500, Loss: 0.005184167175247879\n",
      "Epoch 58600, Loss: 0.005181971446494495\n",
      "Epoch 58700, Loss: 0.005179779329841057\n",
      "Epoch 58800, Loss: 0.005177590827569954\n",
      "Epoch 58900, Loss: 0.0051754059411607415\n",
      "Epoch 59000, Loss: 0.0051732246712994714\n",
      "Epoch 59100, Loss: 0.005171047017890193\n",
      "Epoch 59200, Loss: 0.005168872980068378\n",
      "Epoch 59300, Loss: 0.005166702556216084\n",
      "Epoch 59400, Loss: 0.005164535743978662\n",
      "Epoch 59500, Loss: 0.005162372540282775\n",
      "Epoch 59600, Loss: 0.005160212941355589\n",
      "Epoch 59700, Loss: 0.005158056942744905\n",
      "Epoch 59800, Loss: 0.005155904539340102\n",
      "Epoch 59900, Loss: 0.005153755725393707\n",
      "Epoch 60000, Loss: 0.005151610494543433\n",
      "Epoch 60100, Loss: 0.005149468839834575\n",
      "Epoch 60200, Loss: 0.005147330753742606\n",
      "Epoch 60300, Loss: 0.005145196228195868\n",
      "Epoch 60400, Loss: 0.005143065254598236\n",
      "Epoch 60500, Loss: 0.005140937823851704\n",
      "Epoch 60600, Loss: 0.005138813926378728\n",
      "Epoch 60700, Loss: 0.005136693552144334\n",
      "Epoch 60800, Loss: 0.005134576690677863\n",
      "Epoch 60900, Loss: 0.005132463331094325\n",
      "Epoch 61000, Loss: 0.005130353462115307\n",
      "Epoch 61100, Loss: 0.005128247072089395\n",
      "Epoch 61200, Loss: 0.005126144149012067\n",
      "Epoch 61300, Loss: 0.005124044680545037\n",
      "Epoch 61400, Loss: 0.005121948654035031\n",
      "Epoch 61500, Loss: 0.005119856056531985\n",
      "Epoch 61600, Loss: 0.0051177668748066075\n",
      "Epoch 61700, Loss: 0.005115681095367397\n",
      "Epoch 61800, Loss: 0.005113598704476993\n",
      "Epoch 61900, Loss: 0.005111519688167953\n",
      "Epoch 62000, Loss: 0.005109444032257927\n",
      "Epoch 62100, Loss: 0.005107371722364204\n",
      "Epoch 62200, Loss: 0.005105302743917716\n",
      "Epoch 62300, Loss: 0.005103237082176413\n",
      "Epoch 62400, Loss: 0.005101174722238103\n",
      "Epoch 62500, Loss: 0.00509911564905274\n",
      "Epoch 62600, Loss: 0.005097059847434135\n",
      "Epoch 62700, Loss: 0.005095007302071175\n",
      "Epoch 62800, Loss: 0.005092957997538519\n",
      "Epoch 62900, Loss: 0.0050909119183068\n",
      "Epoch 63000, Loss: 0.005088869048752328\n",
      "Epoch 63100, Loss: 0.005086829373166362\n",
      "Epoch 63200, Loss: 0.00508479287576389\n",
      "Epoch 63300, Loss: 0.00508275954069203\n",
      "Epoch 63400, Loss: 0.005080729352037959\n",
      "Epoch 63500, Loss: 0.005078702293836461\n",
      "Epoch 63600, Loss: 0.005076678350077118\n",
      "Epoch 63700, Loss: 0.005074657504711072\n",
      "Epoch 63800, Loss: 0.0050726397416574745\n",
      "Epoch 63900, Loss: 0.005070625044809582\n",
      "Epoch 64000, Loss: 0.005068613398040504\n",
      "Epoch 64100, Loss: 0.005066604785208657\n",
      "Epoch 64200, Loss: 0.0050645991901629266\n",
      "Epoch 64300, Loss: 0.005062596596747496\n",
      "Epoch 64400, Loss: 0.005060596988806444\n",
      "Epoch 64500, Loss: 0.00505860035018806\n",
      "Epoch 64600, Loss: 0.005056606664748901\n",
      "Epoch 64700, Loss: 0.0050546159163576175\n",
      "Epoch 64800, Loss: 0.0050526280888985526\n",
      "Epoch 64900, Loss: 0.005050643166275108\n",
      "Epoch 65000, Loss: 0.005048661132412922\n",
      "Epoch 65100, Loss: 0.005046681971262825\n",
      "Epoch 65200, Loss: 0.005044705666803638\n",
      "Epoch 65300, Loss: 0.005042732203044756\n",
      "Epoch 65400, Loss: 0.005040761564028612\n",
      "Epoch 65500, Loss: 0.00503879373383292\n",
      "Epoch 65600, Loss: 0.005036828696572827\n",
      "Epoch 65700, Loss: 0.0050348664364028755\n",
      "Epoch 65800, Loss: 0.005032906937518877\n",
      "Epoch 65900, Loss: 0.005030950184159613\n",
      "Epoch 66000, Loss: 0.005028996160608455\n",
      "Epoch 66100, Loss: 0.005027044851194862\n",
      "Epoch 66200, Loss: 0.005025096240295761\n",
      "Epoch 66300, Loss: 0.005023150312336868\n",
      "Epoch 66400, Loss: 0.005021207051793877\n",
      "Epoch 66500, Loss: 0.005019266443193599\n",
      "Epoch 66600, Loss: 0.005017328471115012\n",
      "Epoch 66700, Loss: 0.005015393120190244\n",
      "Epoch 66800, Loss: 0.005013460375105497\n",
      "Epoch 66900, Loss: 0.005011530220601904\n",
      "Epoch 67000, Loss: 0.005009602641476338\n",
      "Epoch 67100, Loss: 0.0050076776225821875\n",
      "Epoch 67200, Loss: 0.005005755148830069\n",
      "Epoch 67300, Loss: 0.005003835205188516\n",
      "Epoch 67400, Loss: 0.005001917776684638\n",
      "Epoch 67500, Loss: 0.0050000028484047405\n",
      "Training complete and model saved!\n",
      "Predicted letter: M\n",
      "Predicted letter: A\n",
      "Predicted letter: B\n",
      "Predicted letter: C\n",
      "Predicted letter: P\n",
      "Predicted letter: D\n",
      "Predicted letter: E\n",
      "Predicted letter: F\n",
      "Predicted letter: C\n",
      "Predicted letter: G\n",
      "Predicted letter: H\n",
      "Predicted letter: L\n",
      "Predicted letter: I\n",
      "Predicted letter: J\n",
      "Predicted letter: K\n",
      "Predicted letter: M\n",
      "Predicted letter: L\n",
      "Predicted letter: N\n",
      "Predicted letter: J\n",
      "Predicted letter: D\n",
      "Predicted letter: O\n",
      "Predicted letter: P\n",
      "Predicted letter: G\n",
      "Predicted letter: Q\n",
      "Predicted letter: P\n",
      "Predicted letter: F\n",
      "Predicted letter: R\n",
      "Predicted letter: S\n",
      "Predicted letter: I\n",
      "Predicted letter: T\n",
      "Predicted letter: N\n",
      "Predicted letter: V\n",
      "Predicted letter: R\n",
      "Predicted letter: N\n",
      "Predicted letter: V\n",
      "Predicted letter: W\n",
      "Predicted letter: S\n",
      "Predicted letter: V\n",
      "Predicted letter: L\n",
      "Predicted letter: V\n",
      "Predicted letter: Z\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import tkinter as tk\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Loss function: Mean Squared Error\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Neural Network class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.bias1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        d_a2 = self.a2 - y\n",
    "        d_z2 = d_a2 * sigmoid_derivative(self.a2)\n",
    "        d_weights2 = np.dot(self.a1.T, d_z2) / m\n",
    "        d_bias2 = np.sum(d_z2, axis=0, keepdims=True) / m\n",
    "\n",
    "        d_a1 = np.dot(d_z2, self.weights2.T)\n",
    "        d_z1 = d_a1 * sigmoid_derivative(self.a1)\n",
    "        d_weights1 = np.dot(X.T, d_z1) / m\n",
    "        d_bias1 = np.sum(d_z1, axis=0, keepdims=True) / m\n",
    "\n",
    "        self.weights1 -= learning_rate * d_weights1\n",
    "        self.bias1 -= learning_rate * d_bias1\n",
    "        self.weights2 -= learning_rate * d_weights2\n",
    "        self.bias2 -= learning_rate * d_bias2\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = mse_loss(y, y_pred)\n",
    "            if loss < 0.005:\n",
    "                break\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        model_data = {\n",
    "            \"weights1\": self.weights1.tolist(),\n",
    "            \"bias1\": self.bias1.tolist(),\n",
    "            \"weights2\": self.weights2.tolist(),\n",
    "            \"bias2\": self.bias2.tolist()\n",
    "        }\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(model_data, f)\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            model_data = json.load(f)\n",
    "            self.weights1 = np.array(model_data[\"weights1\"])\n",
    "            self.bias1 = np.array(model_data[\"bias1\"])\n",
    "            self.weights2 = np.array(model_data[\"weights2\"])\n",
    "            self.bias2 = np.array(model_data[\"bias2\"])\n",
    "\n",
    "# Initialize global variables\n",
    "canvas_size = (100, 100)  # Canvas dimensions (larger canvas for drawing)\n",
    "input_size = (28, 28)  # Neural network input size (fixed at 28x28)\n",
    "draw_color = 0  # Black\n",
    "background_color = 255  # White\n",
    "image = Image.new(\"L\", canvas_size, background_color)\n",
    "draw = ImageDraw.Draw(image)\n",
    "data_collected = []\n",
    "model_file = \"saved_model.json\"\n",
    "dataset_path = \"dataset\"\n",
    "n = NeuralNetwork(input_size=784, hidden_size=128, output_size=26)\n",
    "\n",
    "# Ensure the dataset folder exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "    for letter in range(26):\n",
    "        os.makedirs(os.path.join(dataset_path, chr(ord('A') + letter)))\n",
    "\n",
    "# Load model if it exists\n",
    "if os.path.exists(model_file):\n",
    "    n.load_model(model_file)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"No saved model found. Starting fresh.\")\n",
    "\n",
    "# Function to draw on the canvas\n",
    "def draw_on_canvas(event):\n",
    "    x, y = event.x, event.y\n",
    "    draw.ellipse([x, y, x + 5, y + 5], fill=draw_color)\n",
    "    canvas.create_oval(x, y, x + 5, y + 5, fill=\"black\")\n",
    "\n",
    "# Function to augment the image\n",
    "def augment_image(image, num_augmentations=10):\n",
    "    augmented_images = []\n",
    "    for _ in range(num_augmentations):\n",
    "        # Random transformations\n",
    "        angle = np.random.uniform(-15, 15)  # Rotate by a random angle\n",
    "        scale = np.random.uniform(0.9, 1.1)  # Random scaling\n",
    "        translate_x = np.random.randint(-5, 6)  # Random translation (x-axis)\n",
    "        translate_y = np.random.randint(-5, 6)  # Random translation (y-axis)\n",
    "\n",
    "        # Apply transformations\n",
    "        augmented = image.copy()\n",
    "        augmented = augmented.rotate(angle, fillcolor=background_color)\n",
    "        augmented = augmented.resize(\n",
    "            (int(canvas_size[0] * scale), int(canvas_size[1] * scale)),\n",
    "            resample=Image.BILINEAR\n",
    "        )\n",
    "        augmented = augmented.crop((translate_x, translate_y, canvas_size[0] + translate_x, canvas_size[1] + translate_y))\n",
    "        augmented = augmented.resize(canvas_size)  # Restore to original size\n",
    "\n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 10, (canvas_size[1], canvas_size[0]))\n",
    "        augmented_array = np.array(augmented) + noise\n",
    "        augmented_array = np.clip(augmented_array, 0, 255).astype('uint8')\n",
    "        augmented = Image.fromarray(augmented_array)\n",
    "\n",
    "        # Fill the black slivers with white (background color)\n",
    "        augmented = augmented.convert(\"RGB\")\n",
    "        augmented = augmented.crop((5, 5, canvas_size[0]-5, canvas_size[1]-5))  # Optional crop to remove black slivers\n",
    "\n",
    "        augmented_images.append(augmented)\n",
    "    return augmented_images\n",
    "\n",
    "# Function to save the drawn image into the dataset\n",
    "def save_image():\n",
    "    global data_collected\n",
    "    img_resized = image.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "    binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Ensure binary_image has the correct shape (784,)\n",
    "    if binary_image.shape != (784,):\n",
    "        print(\"Error: Image shape is not consistent.\")\n",
    "        return\n",
    "\n",
    "    label = input_box.get().strip().upper()\n",
    "    if len(label) != 1 or not label.isalpha():\n",
    "        print(\"Please enter a single valid letter.\")\n",
    "        return\n",
    "    label_index = ord(label) - ord('A')\n",
    "    data_collected.append((binary_image, label_index))\n",
    "    print(\"Image saved with label:\", label)\n",
    "\n",
    "    # Save the image in the dataset folder\n",
    "    letter_folder = os.path.join(dataset_path, label)\n",
    "    file_count = len(os.listdir(letter_folder))\n",
    "    original_file = os.path.join(letter_folder, f\"{file_count + 1}.png\")\n",
    "    img_resized.save(original_file)\n",
    "\n",
    "    # Generate and save augmented images\n",
    "    augmented_images = augment_image(img_resized)\n",
    "    for i, aug_img in enumerate(augmented_images, start=1):\n",
    "        aug_file = os.path.join(letter_folder, f\"{file_count + 1}_{i}.png\")\n",
    "        aug_img.save(aug_file)\n",
    "    print(f\"Original and augmented images saved for letter '{label}'.\")\n",
    "\n",
    "# Function to load dataset for training\n",
    "def load_dataset():\n",
    "    data = []\n",
    "    for letter in range(26):\n",
    "        letter_folder = os.path.join(dataset_path, chr(ord('A') + letter))\n",
    "        for file_name in os.listdir(letter_folder):\n",
    "            image_path = os.path.join(letter_folder, file_name)\n",
    "            img = Image.open(image_path).convert(\"L\")\n",
    "            img_resized = img.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "            binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "            \n",
    "            # Ensure binary_image has the correct shape (784,)\n",
    "            if binary_image.shape != (784,):\n",
    "                print(f\"Error: Image {image_path} has inconsistent shape.\")\n",
    "                continue\n",
    "            \n",
    "            data.append((binary_image, letter))\n",
    "    return data\n",
    "\n",
    "# Function to train the neural network\n",
    "def train_model():\n",
    "    global data_collected\n",
    "    data_collected.extend(load_dataset())\n",
    "    if len(data_collected) == 0:\n",
    "        print(\"No data collected yet!\")\n",
    "        return\n",
    "\n",
    "    X = np.array([x[0] for x in data_collected])\n",
    "    y = np.array([x[1] for x in data_collected]).reshape(-1, 1)\n",
    "    y_one_hot = np.zeros((y.size, 26))  # One-hot encode labels for 26 letters\n",
    "    y_one_hot[np.arange(y.size), y.flatten()] = 1\n",
    "\n",
    "    n.train(X, y_one_hot, epochs=100000, learning_rate=0.1)\n",
    "    n.save_model(model_file)\n",
    "    print(\"Training complete and model saved!\")\n",
    "\n",
    "# Function to predict a letter\n",
    "def predict_letter():\n",
    "    img_resized = image.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "    binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "    prediction = n.predict(binary_image.reshape(1, -1))\n",
    "    predicted_label = chr(np.argmax(prediction) + ord('A'))\n",
    "    print(\"Predicted letter:\", predicted_label)\n",
    "    result_label.config(text=f\"Prediction: {predicted_label}\")\n",
    "\n",
    "# Function to clear the canvas\n",
    "def clear_canvas():\n",
    "    global image, draw\n",
    "    canvas.delete(\"all\")\n",
    "    image = Image.new(\"L\", canvas_size, background_color)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Create the Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Handwriting Recognition Pad\")\n",
    "\n",
    "# Create a canvas for drawing\n",
    "canvas = tk.Canvas(root, width=canvas_size[0], height=canvas_size[1], bg=\"white\")\n",
    "canvas.grid(row=0, column=0, columnspan=4)\n",
    "canvas.bind(\"<B1-Motion>\", draw_on_canvas)\n",
    "\n",
    "# Input box for letter label\n",
    "input_label = tk.Label(root, text=\"Enter Letter:\")\n",
    "input_label.grid(row=1, column=0)\n",
    "input_box = tk.Entry(root)\n",
    "input_box.grid(row=1, column=1)\n",
    "\n",
    "# Buttons for saving, training, predicting, and clearing\n",
    "btn_save = tk.Button(root, text=\"Save Image\", command=save_image)\n",
    "btn_save.grid(row=1, column=2)\n",
    "root.bind(\"<Control-s>\", lambda event: save_image())\n",
    "\n",
    "btn_train = tk.Button(root, text=\"Train Model\", command=train_model)\n",
    "btn_train.grid(row=2, column=0)\n",
    "root.bind(\"<Control-t>\", lambda event: train_model())\n",
    "\n",
    "btn_predict = tk.Button(root, text=\"Predict\", command=predict_letter)\n",
    "btn_predict.grid(row=2, column=1)\n",
    "root.bind(\"<Control-p>\", lambda event: predict_letter())\n",
    "\n",
    "btn_clear = tk.Button(root, text=\"Clear Canvas\", command=clear_canvas)\n",
    "btn_clear.grid(row=2, column=2)\n",
    "root.bind(\"<Control-c>\", lambda event: clear_canvas())\n",
    "\n",
    "# Label to display prediction result\n",
    "result_label = tk.Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.grid(row=3, column=0, columnspan=4)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
