{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Starting fresh.\n",
      "Epoch 0, Loss: 0.24844937144807117\n",
      "Epoch 100, Loss: 0.02817419191204275\n",
      "Epoch 200, Loss: 0.027963722896780136\n",
      "Epoch 300, Loss: 0.027896469917908947\n",
      "Epoch 400, Loss: 0.02786269990952246\n",
      "Epoch 500, Loss: 0.027841718733481412\n",
      "Epoch 600, Loss: 0.02782672949650816\n",
      "Epoch 700, Loss: 0.027814719058223178\n",
      "Epoch 800, Loss: 0.02780396233889523\n",
      "Epoch 900, Loss: 0.02779314837854818\n",
      "Epoch 1000, Loss: 0.02778099720070607\n",
      "Epoch 1100, Loss: 0.027766080212688397\n",
      "Epoch 1200, Loss: 0.02774654552610173\n",
      "Epoch 1300, Loss: 0.02771951214576709\n",
      "Epoch 1400, Loss: 0.027680572776081717\n",
      "Epoch 1500, Loss: 0.027623744579869474\n",
      "Epoch 1600, Loss: 0.02754094700849854\n",
      "Epoch 1700, Loss: 0.02742083780391231\n",
      "Epoch 1800, Loss: 0.02724826509068061\n",
      "Epoch 1900, Loss: 0.027003448128799703\n",
      "Epoch 2000, Loss: 0.02666347350064407\n",
      "Epoch 2100, Loss: 0.026207605040742588\n",
      "Epoch 2200, Loss: 0.025625589603162097\n",
      "Epoch 2300, Loss: 0.02492633268198029\n",
      "Epoch 2400, Loss: 0.024141782209622157\n",
      "Epoch 2500, Loss: 0.023321517236487673\n",
      "Epoch 2600, Loss: 0.022517412458778755\n",
      "Epoch 2700, Loss: 0.02176860347137446\n",
      "Epoch 2800, Loss: 0.021095771160690006\n",
      "Epoch 2900, Loss: 0.020503814679299296\n",
      "Epoch 3000, Loss: 0.019987771773032324\n",
      "Epoch 3100, Loss: 0.019538076387553144\n",
      "Epoch 3200, Loss: 0.01914388711891368\n",
      "Epoch 3300, Loss: 0.018794752858158868\n",
      "Epoch 3400, Loss: 0.01848124160514024\n",
      "Epoch 3500, Loss: 0.01819503982231711\n",
      "Epoch 3600, Loss: 0.017928826707148054\n",
      "Epoch 3700, Loss: 0.017676073173355518\n",
      "Epoch 3800, Loss: 0.017430826529274454\n",
      "Epoch 3900, Loss: 0.017187500539482384\n",
      "Epoch 4000, Loss: 0.01694068030803415\n",
      "Epoch 4100, Loss: 0.01668495494070893\n",
      "Epoch 4200, Loss: 0.016414787438666634\n",
      "Epoch 4300, Loss: 0.01612442618677475\n",
      "Epoch 4400, Loss: 0.015807882698083937\n",
      "Epoch 4500, Loss: 0.01545903495210212\n",
      "Epoch 4600, Loss: 0.01507194665125633\n",
      "Epoch 4700, Loss: 0.01464152016939877\n",
      "Epoch 4800, Loss: 0.014164526431174084\n",
      "Epoch 4900, Loss: 0.013640831158586166\n",
      "Training complete and model saved!\n",
      "Predicted letter: R\n",
      "Predicted letter: Q\n",
      "Predicted letter: W\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import tkinter as tk\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Loss function: Mean Squared Error\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Neural Network class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.bias1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        d_a2 = self.a2 - y\n",
    "        d_z2 = d_a2 * sigmoid_derivative(self.a2)\n",
    "        d_weights2 = np.dot(self.a1.T, d_z2) / m\n",
    "        d_bias2 = np.sum(d_z2, axis=0, keepdims=True) / m\n",
    "\n",
    "        d_a1 = np.dot(d_z2, self.weights2.T)\n",
    "        d_z1 = d_a1 * sigmoid_derivative(self.a1)\n",
    "        d_weights1 = np.dot(X.T, d_z1) / m\n",
    "        d_bias1 = np.sum(d_z1, axis=0, keepdims=True) / m\n",
    "\n",
    "        self.weights1 -= learning_rate * d_weights1\n",
    "        self.bias1 -= learning_rate * d_bias1\n",
    "        self.weights2 -= learning_rate * d_weights2\n",
    "        self.bias2 -= learning_rate * d_bias2\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = mse_loss(y, y_pred)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        model_data = {\n",
    "            \"weights1\": self.weights1.tolist(),\n",
    "            \"bias1\": self.bias1.tolist(),\n",
    "            \"weights2\": self.weights2.tolist(),\n",
    "            \"bias2\": self.bias2.tolist()\n",
    "        }\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(model_data, f)\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            model_data = json.load(f)\n",
    "            self.weights1 = np.array(model_data[\"weights1\"])\n",
    "            self.bias1 = np.array(model_data[\"bias1\"])\n",
    "            self.weights2 = np.array(model_data[\"weights2\"])\n",
    "            self.bias2 = np.array(model_data[\"bias2\"])\n",
    "\n",
    "# Initialize global variables\n",
    "canvas_size = (100, 100)  # Canvas dimensions (larger canvas for drawing)\n",
    "input_size = (28, 28)  # Neural network input size (fixed at 28x28)\n",
    "draw_color = 0  # Black\n",
    "background_color = 255  # White\n",
    "image = Image.new(\"L\", canvas_size, background_color)\n",
    "draw = ImageDraw.Draw(image)\n",
    "data_collected = []\n",
    "model_file = \"saved_model.json\"\n",
    "dataset_path = \"dataset\"\n",
    "n = NeuralNetwork(input_size=784, hidden_size=128, output_size=26)\n",
    "\n",
    "# Ensure the dataset folder exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "    for letter in range(26):\n",
    "        os.makedirs(os.path.join(dataset_path, chr(ord('A') + letter)))\n",
    "\n",
    "# Load model if it exists\n",
    "if os.path.exists(model_file):\n",
    "    n.load_model(model_file)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"No saved model found. Starting fresh.\")\n",
    "\n",
    "# Function to draw on the canvas\n",
    "def draw_on_canvas(event):\n",
    "    x, y = event.x, event.y\n",
    "    draw.ellipse([x, y, x + 5, y + 5], fill=draw_color)\n",
    "    canvas.create_oval(x, y, x + 5, y + 5, fill=\"black\")\n",
    "\n",
    "# Function to augment the image\n",
    "def augment_image(image, num_augmentations=10):\n",
    "    augmented_images = []\n",
    "    for _ in range(num_augmentations):\n",
    "        # Random transformations\n",
    "        angle = np.random.uniform(-15, 15)  # Rotate by a random angle\n",
    "        scale = np.random.uniform(0.9, 1.1)  # Random scaling\n",
    "        translate_x = np.random.randint(-5, 6)  # Random translation (x-axis)\n",
    "        translate_y = np.random.randint(-5, 6)  # Random translation (y-axis)\n",
    "\n",
    "        # Apply transformations\n",
    "        augmented = image.copy()\n",
    "        augmented = augmented.rotate(angle, fillcolor=background_color)\n",
    "        augmented = augmented.resize(\n",
    "            (int(canvas_size[0] * scale), int(canvas_size[1] * scale)),\n",
    "            resample=Image.BILINEAR\n",
    "        )\n",
    "        augmented = augmented.crop((translate_x, translate_y, canvas_size[0] + translate_x, canvas_size[1] + translate_y))\n",
    "        augmented = augmented.resize(canvas_size)  # Restore to original size\n",
    "\n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 10, (canvas_size[1], canvas_size[0]))\n",
    "        augmented_array = np.array(augmented) + noise\n",
    "        augmented_array = np.clip(augmented_array, 0, 255).astype('uint8')\n",
    "        augmented = Image.fromarray(augmented_array)\n",
    "\n",
    "        # Fill the black slivers with white (background color)\n",
    "        augmented = augmented.convert(\"RGB\")\n",
    "        augmented = augmented.crop((5, 5, canvas_size[0]-5, canvas_size[1]-5))  # Optional crop to remove black slivers\n",
    "\n",
    "        augmented_images.append(augmented)\n",
    "    return augmented_images\n",
    "\n",
    "# Function to save the drawn image into the dataset\n",
    "def save_image():\n",
    "    global data_collected\n",
    "    img_resized = image.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "    binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Ensure binary_image has the correct shape (784,)\n",
    "    if binary_image.shape != (784,):\n",
    "        print(\"Error: Image shape is not consistent.\")\n",
    "        return\n",
    "\n",
    "    label = input_box.get().strip().upper()\n",
    "    if len(label) != 1 or not label.isalpha():\n",
    "        print(\"Please enter a single valid letter.\")\n",
    "        return\n",
    "    label_index = ord(label) - ord('A')\n",
    "    data_collected.append((binary_image, label_index))\n",
    "    print(\"Image saved with label:\", label)\n",
    "\n",
    "    # Save the image in the dataset folder\n",
    "    letter_folder = os.path.join(dataset_path, label)\n",
    "    file_count = len(os.listdir(letter_folder))\n",
    "    original_file = os.path.join(letter_folder, f\"{file_count + 1}.png\")\n",
    "    img_resized.save(original_file)\n",
    "\n",
    "    # Generate and save augmented images\n",
    "    augmented_images = augment_image(img_resized)\n",
    "    for i, aug_img in enumerate(augmented_images, start=1):\n",
    "        aug_file = os.path.join(letter_folder, f\"{file_count + 1}_{i}.png\")\n",
    "        aug_img.save(aug_file)\n",
    "    print(f\"Original and augmented images saved for letter '{label}'.\")\n",
    "\n",
    "# Function to load dataset for training\n",
    "def load_dataset():\n",
    "    data = []\n",
    "    for letter in range(26):\n",
    "        letter_folder = os.path.join(dataset_path, chr(ord('A') + letter))\n",
    "        for file_name in os.listdir(letter_folder):\n",
    "            image_path = os.path.join(letter_folder, file_name)\n",
    "            img = Image.open(image_path).convert(\"L\")\n",
    "            img_resized = img.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "            binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "            \n",
    "            # Ensure binary_image has the correct shape (784,)\n",
    "            if binary_image.shape != (784,):\n",
    "                print(f\"Error: Image {image_path} has inconsistent shape.\")\n",
    "                continue\n",
    "            \n",
    "            data.append((binary_image, letter))\n",
    "    return data\n",
    "\n",
    "# Function to train the neural network\n",
    "def train_model():\n",
    "    global data_collected\n",
    "    data_collected.extend(load_dataset())\n",
    "    if len(data_collected) == 0:\n",
    "        print(\"No data collected yet!\")\n",
    "        return\n",
    "\n",
    "    X = np.array([x[0] for x in data_collected])\n",
    "    y = np.array([x[1] for x in data_collected]).reshape(-1, 1)\n",
    "    y_one_hot = np.zeros((y.size, 26))  # One-hot encode labels for 26 letters\n",
    "    y_one_hot[np.arange(y.size), y.flatten()] = 1\n",
    "\n",
    "    n.train(X, y_one_hot, epochs=5000, learning_rate=0.1)\n",
    "    n.save_model(model_file)\n",
    "    print(\"Training complete and model saved!\")\n",
    "\n",
    "# Function to predict a letter\n",
    "def predict_letter():\n",
    "    img_resized = image.resize(input_size)  # Resize to 28x28 for neural network input\n",
    "    binary_image = np.array(img_resized).flatten() / 255.0  # Normalize to [0, 1]\n",
    "    prediction = n.predict(binary_image.reshape(1, -1))\n",
    "    predicted_label = chr(np.argmax(prediction) + ord('A'))\n",
    "    print(\"Predicted letter:\", predicted_label)\n",
    "    result_label.config(text=f\"Prediction: {predicted_label}\")\n",
    "\n",
    "# Function to clear the canvas\n",
    "def clear_canvas():\n",
    "    global image, draw\n",
    "    canvas.delete(\"all\")\n",
    "    image = Image.new(\"L\", canvas_size, background_color)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Create the Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Handwriting Recognition Pad\")\n",
    "\n",
    "# Create a canvas for drawing\n",
    "canvas = tk.Canvas(root, width=canvas_size[0], height=canvas_size[1], bg=\"white\")\n",
    "canvas.grid(row=0, column=0, columnspan=4)\n",
    "canvas.bind(\"<B1-Motion>\", draw_on_canvas)\n",
    "\n",
    "# Input box for letter label\n",
    "input_label = tk.Label(root, text=\"Enter Letter:\")\n",
    "input_label.grid(row=1, column=0)\n",
    "input_box = tk.Entry(root)\n",
    "input_box.grid(row=1, column=1)\n",
    "\n",
    "# Buttons for saving, training, predicting, and clearing\n",
    "btn_save = tk.Button(root, text=\"Save Image\", command=save_image)\n",
    "btn_save.grid(row=1, column=2)\n",
    "root.bind(\"<Control-s>\", lambda event: save_image())\n",
    "\n",
    "btn_train = tk.Button(root, text=\"Train Model\", command=train_model)\n",
    "btn_train.grid(row=2, column=0)\n",
    "root.bind(\"<Control-t>\", lambda event: train_model())\n",
    "\n",
    "btn_predict = tk.Button(root, text=\"Predict\", command=predict_letter)\n",
    "btn_predict.grid(row=2, column=1)\n",
    "root.bind(\"<Control-p>\", lambda event: predict_letter())\n",
    "\n",
    "btn_clear = tk.Button(root, text=\"Clear Canvas\", command=clear_canvas)\n",
    "btn_clear.grid(row=2, column=2)\n",
    "root.bind(\"<Control-c>\", lambda event: clear_canvas())\n",
    "\n",
    "# Label to display prediction result\n",
    "result_label = tk.Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.grid(row=3, column=0, columnspan=4)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
